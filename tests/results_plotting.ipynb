{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from utils.helper_func import *\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=1.3, rc={\"lines.linewidth\": 2.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_files = glob.glob('C:\\\\Users\\\\ekino\\\\OneDrive - UW\\\\GPR\\\\Results\\\\10080\\\\all_results_copy\\\\results_*.csv')\n",
    "params_files = glob.glob('C:\\\\Users\\\\ekino\\\\OneDrive - UW\\\\GPR\\\\Results\\\\10080\\\\all_parameters\\\\params_*.csv')\n",
    "\n",
    "# Loop through each file name and extract unique identifier\n",
    "results_ids = [f.split('_')[3].split('.')[0] for f in results_files]\n",
    "params_ids = [f.split('_')[2].split('.')[0] for f in params_files]\n",
    "\n",
    "mtgp_mae = np.array([])\n",
    "mtgp_rmse = np.array([])\n",
    "mtgp_mad = np.array([])\n",
    "mtgp_mape = np.array([])\n",
    "mtgp_maxape = np.array([])\n",
    "mtgp_tape = np.array([])\n",
    "ses_mae = np.array([])\n",
    "ses_rmse = np.array([])\n",
    "ses_mad = np.array([])\n",
    "ses_mape = np.array([])\n",
    "ses_maxape = np.array([])\n",
    "ses_tape = np.array([])\n",
    "holt_mae = np.array([])\n",
    "holt_rmse = np.array([])\n",
    "holt_mad = np.array([])\n",
    "holt_mape = np.array([])\n",
    "holt_maxape = np.array([])\n",
    "holt_tape = np.array([])\n",
    "es_mae = np.array([])\n",
    "es_rmse = np.array([])\n",
    "es_mad = np.array([])\n",
    "es_mape = np.array([])\n",
    "es_maxape = np.array([])\n",
    "es_tape = np.array([])\n",
    "arima_mae = np.array([])\n",
    "arima_rmse = np.array([])\n",
    "arima_mad = np.array([])\n",
    "arima_mape = np.array([])\n",
    "arima_maxape = np.array([])\n",
    "arima_tape = np.array([])\n",
    "sarima_mae = np.array([])\n",
    "sarima_rmse = np.array([])\n",
    "sarima_mad = np.array([])\n",
    "sarima_mape = np.array([])\n",
    "sarima_maxape = np.array([])\n",
    "sarima_tape = np.array([])\n",
    "new_ocp = np.array([])\n",
    "init_lengthscale = np.array([])\n",
    "bic = np.array([])\n",
    "\n",
    "\n",
    "# Loop through each unique identifier and read corresponding files\n",
    "for id in set(results_ids) & set(params_ids):\n",
    "    result_file = 'C:\\\\Users\\\\ekino\\\\OneDrive - UW\\\\GPR\\\\Results\\\\10080\\\\all_results_copy\\\\results_{}.csv'.format(id)\n",
    "    params_file = 'C:\\\\Users\\\\ekino\\\\OneDrive - UW\\\\GPR\\\\Results\\\\10080\\\\all_parameters\\\\params_{}.csv'.format(id)\n",
    "\n",
    "     # Read both files\n",
    "    res = pd.read_csv(result_file, header=0)\n",
    "    par = pd.read_csv(params_file, header=0)\n",
    "    par.columns = ['param', 'value']\n",
    "\n",
    "    mtgp_mae = np.append(mtgp_mae, res['MAE'][0])\n",
    "    mtgp_rmse = np.append(mtgp_rmse, res['RMSE'][0])\n",
    "    mtgp_mad = np.append(mtgp_mad, res['MAD'][0])\n",
    "    mtgp_mape = np.append(mtgp_mape, res['MAPE'][0])\n",
    "    mtgp_maxape = np.append(mtgp_maxape, res['MAXAPE'][0])\n",
    "    mtgp_tape = np.append(mtgp_tape, res['TAPE'][0])\n",
    "    ses_mae = np.append(ses_mae, res['MAE'][1])\n",
    "    ses_rmse = np.append(ses_rmse, res['RMSE'][1])\n",
    "    ses_mad = np.append(ses_mad, res['MAD'][1])\n",
    "    ses_mape = np.append(ses_mape, res['MAPE'][1])\n",
    "    ses_maxape = np.append(ses_maxape, res['MAXAPE'][1])\n",
    "    ses_tape = np.append(ses_tape, res['TAPE'][1])\n",
    "    holt_mae = np.append(holt_mae, res['MAE'][2])\n",
    "    holt_rmse = np.append(holt_rmse, res['RMSE'][2])\n",
    "    holt_mad = np.append(holt_mad, res['MAD'][2])\n",
    "    holt_mape = np.append(holt_mape, res['MAPE'][2])\n",
    "    holt_maxape = np.append(holt_maxape, res['MAXAPE'][2])\n",
    "    holt_tape = np.append(holt_tape, res['TAPE'][2])\n",
    "    es_mae = np.append(es_mae, res['MAE'][3])\n",
    "    es_rmse = np.append(es_rmse, res['RMSE'][3])\n",
    "    es_mad = np.append(es_mad, res['MAD'][3])\n",
    "    es_mape = np.append(es_mape, res['MAPE'][3])\n",
    "    es_maxape = np.append(es_maxape, res['MAXAPE'][3])\n",
    "    es_tape = np.append(es_tape, res['TAPE'][3])\n",
    "    arima_mae = np.append(arima_mae, res['MAE'][4])\n",
    "    arima_rmse = np.append(arima_rmse, res['RMSE'][4])\n",
    "    arima_mad = np.append(arima_mad, res['MAD'][4])\n",
    "    arima_mape = np.append(arima_mape, res['MAPE'][4])\n",
    "    arima_maxape = np.append(arima_maxape, res['MAXAPE'][4])\n",
    "    arima_tape = np.append(arima_tape, res['TAPE'][4])\n",
    "    sarima_mae = np.append(sarima_mae, res['MAE'][5])\n",
    "    sarima_rmse = np.append(sarima_rmse, res['RMSE'][5])\n",
    "    sarima_mad = np.append(sarima_mad, res['MAD'][5])\n",
    "    sarima_mape = np.append(sarima_mape, res['MAPE'][5])\n",
    "    sarima_maxape = np.append(sarima_maxape, res['MAXAPE'][5])\n",
    "    sarima_tape = np.append(sarima_tape, res['TAPE'][5])\n",
    "    new_ocp = np.append(new_ocp, par[par['param'] == 'new_ocp'].value.astype(float))\n",
    "    init_lengthscale = np.append(init_lengthscale, par[par['param'] == 'init_lengthscale'].value.astype(float))\n",
    "    bic = np.append(bic, par[par['param'] == 'bic'].value.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTempOcpvsError(mtgp_mae, new_ocp, fitline=True, title=r'$\\tau = 1$ week', xlabel='Temporal occupancy', ylabel='MAE', figsize=(8,6), c='b', marker='o', label='MTGP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a boxplot of each metric for each model\n",
    "plt.figure(figsize=(15, 5))\n",
    "# Set title, write in latex\n",
    "plt.suptitle(r'$\\tau = 1$ week', fontsize=20)\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.boxplot([mtgp_mae, ses_mae, holt_mae, es_mae, arima_mae, sarima_mae])\n",
    "plt.title('MAE')\n",
    "plt.xticks([1, 2, 3, 4, 5, 6], [r'$\\bf{MTGP}$', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX'])\n",
    "plt.ylim(0, 6)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.boxplot([mtgp_rmse, ses_rmse, holt_rmse, es_rmse, arima_rmse, sarima_rmse])\n",
    "plt.title('RMSE')\n",
    "plt.ylim(0, 6)\n",
    "plt.xticks([1, 2, 3, 4, 5, 6], [r'$\\bf{MTGP}$', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX'])\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.boxplot([mtgp_mad, ses_mad, holt_mad, es_mad, arima_mad, sarima_mad])\n",
    "plt.title('MAD')\n",
    "plt.ylim(0, 6)\n",
    "plt.xticks([1, 2, 3, 4, 5, 6], [r'$\\bf{MTGP}$', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_files = glob.glob('C:\\\\Users\\\\ekino\\\\OneDrive - UW\\\\GPR\\\\Results\\\\1440\\\\all_results_copy\\\\results_*.csv')\n",
    "params_files = glob.glob('C:\\\\Users\\\\ekino\\\\OneDrive - UW\\\\GPR\\\\Results\\\\1440\\\\all_parameters\\\\params_*.csv')\n",
    "\n",
    "# Loop through each file name and extract unique identifier\n",
    "results_ids = [f.split('_')[3].split('.')[0] for f in results_files]\n",
    "params_ids = [f.split('_')[2].split('.')[0] for f in params_files]\n",
    "\n",
    "mtgp_mae = np.array([])\n",
    "mtgp_rmse = np.array([])\n",
    "mtgp_mad = np.array([])\n",
    "mtgp_mape = np.array([])\n",
    "mtgp_maxape = np.array([])\n",
    "mtgp_tape = np.array([])\n",
    "ses_mae = np.array([])\n",
    "ses_rmse = np.array([])\n",
    "ses_mad = np.array([])\n",
    "ses_mape = np.array([])\n",
    "ses_maxape = np.array([])\n",
    "ses_tape = np.array([])\n",
    "holt_mae = np.array([])\n",
    "holt_rmse = np.array([])\n",
    "holt_mad = np.array([])\n",
    "holt_mape = np.array([])\n",
    "holt_maxape = np.array([])\n",
    "holt_tape = np.array([])\n",
    "es_mae = np.array([])\n",
    "es_rmse = np.array([])\n",
    "es_mad = np.array([])\n",
    "es_mape = np.array([])\n",
    "es_maxape = np.array([])\n",
    "es_tape = np.array([])\n",
    "arima_mae = np.array([])\n",
    "arima_rmse = np.array([])\n",
    "arima_mad = np.array([])\n",
    "arima_mape = np.array([])\n",
    "arima_maxape = np.array([])\n",
    "arima_tape = np.array([])\n",
    "sarima_mae = np.array([])\n",
    "sarima_rmse = np.array([])\n",
    "sarima_mad = np.array([])\n",
    "sarima_mape = np.array([])\n",
    "sarima_maxape = np.array([])\n",
    "sarima_tape = np.array([])\n",
    "new_ocp = np.array([])\n",
    "init_lengthscale = np.array([])\n",
    "bic = np.array([])\n",
    "\n",
    "\n",
    "# Loop through each unique identifier and read corresponding files\n",
    "for id in set(results_ids) & set(params_ids):\n",
    "    result_file = 'C:\\\\Users\\\\ekino\\\\OneDrive - UW\\\\GPR\\\\Results\\\\1440\\\\all_results_copy\\\\results_{}.csv'.format(id)\n",
    "    params_file = 'C:\\\\Users\\\\ekino\\\\OneDrive - UW\\\\GPR\\\\Results\\\\1440\\\\all_parameters\\\\params_{}.csv'.format(id)\n",
    "\n",
    "     # Read both files\n",
    "    res = pd.read_csv(result_file, header=0)\n",
    "    par = pd.read_csv(params_file, header=0)\n",
    "    par.columns = ['param', 'value']\n",
    "\n",
    "    mtgp_mae = np.append(mtgp_mae, res['MAE'][0])\n",
    "    mtgp_rmse = np.append(mtgp_rmse, res['RMSE'][0])\n",
    "    mtgp_mad = np.append(mtgp_mad, res['MAD'][0])\n",
    "    mtgp_mape = np.append(mtgp_mape, res['MAPE'][0])\n",
    "    mtgp_maxape = np.append(mtgp_maxape, res['MAXAPE'][0])\n",
    "    mtgp_tape = np.append(mtgp_tape, res['TAPE'][0])\n",
    "    ses_mae = np.append(ses_mae, res['MAE'][1])\n",
    "    ses_rmse = np.append(ses_rmse, res['RMSE'][1])\n",
    "    ses_mad = np.append(ses_mad, res['MAD'][1])\n",
    "    ses_mape = np.append(ses_mape, res['MAPE'][1])\n",
    "    ses_maxape = np.append(ses_maxape, res['MAXAPE'][1])\n",
    "    ses_tape = np.append(ses_tape, res['TAPE'][1])\n",
    "    holt_mae = np.append(holt_mae, res['MAE'][2])\n",
    "    holt_rmse = np.append(holt_rmse, res['RMSE'][2])\n",
    "    holt_mad = np.append(holt_mad, res['MAD'][2])\n",
    "    holt_mape = np.append(holt_mape, res['MAPE'][2])\n",
    "    holt_maxape = np.append(holt_maxape, res['MAXAPE'][2])\n",
    "    holt_tape = np.append(holt_tape, res['TAPE'][2])\n",
    "    es_mae = np.append(es_mae, res['MAE'][3])\n",
    "    es_rmse = np.append(es_rmse, res['RMSE'][3])\n",
    "    es_mad = np.append(es_mad, res['MAD'][3])\n",
    "    es_mape = np.append(es_mape, res['MAPE'][3])\n",
    "    es_maxape = np.append(es_maxape, res['MAXAPE'][3])\n",
    "    es_tape = np.append(es_tape, res['TAPE'][3])\n",
    "    arima_mae = np.append(arima_mae, res['MAE'][4])\n",
    "    arima_rmse = np.append(arima_rmse, res['RMSE'][4])\n",
    "    arima_mad = np.append(arima_mad, res['MAD'][4])\n",
    "    arima_mape = np.append(arima_mape, res['MAPE'][4])\n",
    "    arima_maxape = np.append(arima_maxape, res['MAXAPE'][4])\n",
    "    arima_tape = np.append(arima_tape, res['TAPE'][4])\n",
    "    sarima_mae = np.append(sarima_mae, res['MAE'][5])\n",
    "    sarima_rmse = np.append(sarima_rmse, res['RMSE'][5])\n",
    "    sarima_mad = np.append(sarima_mad, res['MAD'][5])\n",
    "    sarima_mape = np.append(sarima_mape, res['MAPE'][5])\n",
    "    sarima_maxape = np.append(sarima_maxape, res['MAXAPE'][5])\n",
    "    sarima_tape = np.append(sarima_tape, res['TAPE'][5])\n",
    "    new_ocp = np.append(new_ocp, par[par['param'] == 'new_ocp'].value.astype(float))\n",
    "    init_lengthscale = np.append(init_lengthscale, par[par['param'] == 'init_lengthscale'].value.astype(float))\n",
    "    bic = np.append(bic, par[par['param'] == 'bic'].value.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTempOcpvsError(mtgp_mae, new_ocp, fitline=True, title=r'$\\tau = 1$ day', xlabel='Temporal occupancy', ylabel='MAE', figsize=(8,6), c='b', marker='o', label='MTGP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=1.3, rc={\"lines.linewidth\": 2.5})\n",
    "plt.figure(figsize=(15, 5))\n",
    "# Set title, write in latex\n",
    "plt.suptitle(r'$\\tau = 1$ day', fontsize=20)\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.boxplot([mtgp_mae, ses_mae, holt_mae, es_mae, arima_mae, sarima_mae])\n",
    "plt.title('MAE')\n",
    "plt.xticks([1, 2, 3, 4, 5, 6], [r'$\\bf{MTGP}$', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX'])\n",
    "plt.ylim(0, 6)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.boxplot([mtgp_rmse, ses_rmse, holt_rmse, es_rmse, arima_rmse, sarima_rmse])\n",
    "plt.title('RMSE')\n",
    "plt.ylim(0, 6)\n",
    "plt.xticks([1, 2, 3, 4, 5, 6], [r'$\\bf{MTGP}$', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX'])\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.boxplot([mtgp_mad, ses_mad, holt_mad, es_mad, arima_mad, sarima_mad])\n",
    "plt.title('MAD')\n",
    "plt.ylim(0, 4)\n",
    "plt.xticks([1, 2, 3, 4, 5, 6], [r'$\\bf{MTGP}$', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_files = glob.glob('C:\\\\Users\\\\ekino\\\\OneDrive - UW\\\\GPR\\\\Results\\\\360\\\\all_results_copy\\\\results_*.csv')\n",
    "params_files = glob.glob('C:\\\\Users\\\\ekino\\\\OneDrive - UW\\\\GPR\\\\Results\\\\360\\\\all_parameters\\\\params_*.csv')\n",
    "\n",
    "# Loop through each file name and extract unique identifier\n",
    "results_ids = [f.split('_')[3].split('.')[0] for f in results_files]\n",
    "params_ids = [f.split('_')[2].split('.')[0] for f in params_files]\n",
    "\n",
    "mtgp_mae = np.array([])\n",
    "mtgp_rmse = np.array([])\n",
    "mtgp_mad = np.array([])\n",
    "mtgp_mape = np.array([])\n",
    "mtgp_maxape = np.array([])\n",
    "mtgp_tape = np.array([])\n",
    "ses_mae = np.array([])\n",
    "ses_rmse = np.array([])\n",
    "ses_mad = np.array([])\n",
    "ses_mape = np.array([])\n",
    "ses_maxape = np.array([])\n",
    "ses_tape = np.array([])\n",
    "holt_mae = np.array([])\n",
    "holt_rmse = np.array([])\n",
    "holt_mad = np.array([])\n",
    "holt_mape = np.array([])\n",
    "holt_maxape = np.array([])\n",
    "holt_tape = np.array([])\n",
    "es_mae = np.array([])\n",
    "es_rmse = np.array([])\n",
    "es_mad = np.array([])\n",
    "es_mape = np.array([])\n",
    "es_maxape = np.array([])\n",
    "es_tape = np.array([])\n",
    "arima_mae = np.array([])\n",
    "arima_rmse = np.array([])\n",
    "arima_mad = np.array([])\n",
    "arima_mape = np.array([])\n",
    "arima_maxape = np.array([])\n",
    "arima_tape = np.array([])\n",
    "sarima_mae = np.array([])\n",
    "sarima_rmse = np.array([])\n",
    "sarima_mad = np.array([])\n",
    "sarima_mape = np.array([])\n",
    "sarima_maxape = np.array([])\n",
    "sarima_tape = np.array([])\n",
    "new_ocp = np.array([])\n",
    "init_lengthscale = np.array([])\n",
    "bic = np.array([])\n",
    "\n",
    "\n",
    "# Loop through each unique identifier and read corresponding files\n",
    "for id in set(results_ids) & set(params_ids):\n",
    "    result_file = 'C:\\\\Users\\\\ekino\\\\OneDrive - UW\\\\GPR\\\\Results\\\\360\\\\all_results_copy\\\\results_{}.csv'.format(id)\n",
    "    params_file = 'C:\\\\Users\\\\ekino\\\\OneDrive - UW\\\\GPR\\\\Results\\\\360\\\\all_parameters\\\\params_{}.csv'.format(id)\n",
    "\n",
    "     # Read both files\n",
    "    res = pd.read_csv(result_file, header=0)\n",
    "    par = pd.read_csv(params_file, header=0)\n",
    "    par.columns = ['param', 'value']\n",
    "\n",
    "    mtgp_mae = np.append(mtgp_mae, res['MAE'][0])\n",
    "    mtgp_rmse = np.append(mtgp_rmse, res['RMSE'][0])\n",
    "    mtgp_mad = np.append(mtgp_mad, res['MAD'][0])\n",
    "    mtgp_mape = np.append(mtgp_mape, res['MAPE'][0])\n",
    "    mtgp_maxape = np.append(mtgp_maxape, res['MAXAPE'][0])\n",
    "    mtgp_tape = np.append(mtgp_tape, res['TAPE'][0])\n",
    "    ses_mae = np.append(ses_mae, res['MAE'][1])\n",
    "    ses_rmse = np.append(ses_rmse, res['RMSE'][1])\n",
    "    ses_mad = np.append(ses_mad, res['MAD'][1])\n",
    "    ses_mape = np.append(ses_mape, res['MAPE'][1])\n",
    "    ses_maxape = np.append(ses_maxape, res['MAXAPE'][1])\n",
    "    ses_tape = np.append(ses_tape, res['TAPE'][1])\n",
    "    holt_mae = np.append(holt_mae, res['MAE'][2])\n",
    "    holt_rmse = np.append(holt_rmse, res['RMSE'][2])\n",
    "    holt_mad = np.append(holt_mad, res['MAD'][2])\n",
    "    holt_mape = np.append(holt_mape, res['MAPE'][2])\n",
    "    holt_maxape = np.append(holt_maxape, res['MAXAPE'][2])\n",
    "    holt_tape = np.append(holt_tape, res['TAPE'][2])\n",
    "    es_mae = np.append(es_mae, res['MAE'][3])\n",
    "    es_rmse = np.append(es_rmse, res['RMSE'][3])\n",
    "    es_mad = np.append(es_mad, res['MAD'][3])\n",
    "    es_mape = np.append(es_mape, res['MAPE'][3])\n",
    "    es_maxape = np.append(es_maxape, res['MAXAPE'][3])\n",
    "    es_tape = np.append(es_tape, res['TAPE'][3])\n",
    "    arima_mae = np.append(arima_mae, res['MAE'][4])\n",
    "    arima_rmse = np.append(arima_rmse, res['RMSE'][4])\n",
    "    arima_mad = np.append(arima_mad, res['MAD'][4])\n",
    "    arima_mape = np.append(arima_mape, res['MAPE'][4])\n",
    "    arima_maxape = np.append(arima_maxape, res['MAXAPE'][4])\n",
    "    arima_tape = np.append(arima_tape, res['TAPE'][4])\n",
    "    sarima_mae = np.append(sarima_mae, res['MAE'][5])\n",
    "    sarima_rmse = np.append(sarima_rmse, res['RMSE'][5])\n",
    "    sarima_mad = np.append(sarima_mad, res['MAD'][5])\n",
    "    sarima_mape = np.append(sarima_mape, res['MAPE'][5])\n",
    "    sarima_maxape = np.append(sarima_maxape, res['MAXAPE'][5])\n",
    "    sarima_tape = np.append(sarima_tape, res['TAPE'][5])\n",
    "    new_ocp = np.append(new_ocp, par[par['param'] == 'new_ocp'].value.astype(float))\n",
    "    init_lengthscale = np.append(init_lengthscale, par[par['param'] == 'init_lengthscale'].value.astype(float))\n",
    "    bic = np.append(bic, par[par['param'] == 'bic'].value.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTempOcpvsError(mtgp_mae, new_ocp, fitline=True, title=r'$\\tau = 6$ hours', xlabel='Temporal occupancy', ylabel='MAE', figsize=(8,6), c='b', marker='o', label='MTGP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=1.3, rc={\"lines.linewidth\": 2.5})\n",
    "plt.figure(figsize=(15, 5))\n",
    "# Set title, write in latex\n",
    "plt.suptitle(r'$\\tau = 6$ hours', fontsize=20)\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.boxplot([mtgp_mae, ses_mae, holt_mae, es_mae, arima_mae, sarima_mae])\n",
    "plt.title('MAE')\n",
    "plt.xticks([1, 2, 3, 4, 5, 6], [r'$\\bf{MTGP}$', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX'])\n",
    "plt.ylim(0, 6)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.boxplot([mtgp_rmse, ses_rmse, holt_rmse, es_rmse, arima_rmse, sarima_rmse])\n",
    "plt.title('RMSE')\n",
    "plt.ylim(0, 6)\n",
    "plt.xticks([1, 2, 3, 4, 5, 6], [r'$\\bf{MTGP}$', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX'])\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.boxplot([mtgp_mad, ses_mad, holt_mad, es_mad, arima_mad, sarima_mad])\n",
    "plt.title('MAD')\n",
    "plt.ylim(0, 4)\n",
    "plt.xticks([1, 2, 3, 4, 5, 6], [r'$\\bf{MTGP}$', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_files = glob.glob('C:\\\\Users\\\\ekino\\\\OneDrive - UW\\\\GPR\\\\Results\\\\60\\\\all_results_copy\\\\results_*.csv')\n",
    "params_files = glob.glob('C:\\\\Users\\\\ekino\\\\OneDrive - UW\\\\GPR\\\\Results\\\\60\\\\all_parameters\\\\params_*.csv')\n",
    "\n",
    "# Loop through each file name and extract unique identifier\n",
    "results_ids = [f.split('_')[3].split('.')[0] for f in results_files]\n",
    "params_ids = [f.split('_')[2].split('.')[0] for f in params_files]\n",
    "\n",
    "mtgp_mae = np.array([])\n",
    "mtgp_rmse = np.array([])\n",
    "mtgp_mad = np.array([])\n",
    "mtgp_mape = np.array([])\n",
    "mtgp_maxape = np.array([])\n",
    "mtgp_tape = np.array([])\n",
    "ses_mae = np.array([])\n",
    "ses_rmse = np.array([])\n",
    "ses_mad = np.array([])\n",
    "ses_mape = np.array([])\n",
    "ses_maxape = np.array([])\n",
    "ses_tape = np.array([])\n",
    "holt_mae = np.array([])\n",
    "holt_rmse = np.array([])\n",
    "holt_mad = np.array([])\n",
    "holt_mape = np.array([])\n",
    "holt_maxape = np.array([])\n",
    "holt_tape = np.array([])\n",
    "es_mae = np.array([])\n",
    "es_rmse = np.array([])\n",
    "es_mad = np.array([])\n",
    "es_mape = np.array([])\n",
    "es_maxape = np.array([])\n",
    "es_tape = np.array([])\n",
    "arima_mae = np.array([])\n",
    "arima_rmse = np.array([])\n",
    "arima_mad = np.array([])\n",
    "arima_mape = np.array([])\n",
    "arima_maxape = np.array([])\n",
    "arima_tape = np.array([])\n",
    "sarima_mae = np.array([])\n",
    "sarima_rmse = np.array([])\n",
    "sarima_mad = np.array([])\n",
    "sarima_mape = np.array([])\n",
    "sarima_maxape = np.array([])\n",
    "sarima_tape = np.array([])\n",
    "new_ocp = np.array([])\n",
    "init_lengthscale = np.array([])\n",
    "bic = np.array([])\n",
    "\n",
    "\n",
    "# Loop through each unique identifier and read corresponding files\n",
    "for id in set(results_ids) & set(params_ids):\n",
    "    result_file = 'C:\\\\Users\\\\ekino\\\\OneDrive - UW\\\\GPR\\\\Results\\\\60\\\\all_results_copy\\\\results_{}.csv'.format(id)\n",
    "    params_file = 'C:\\\\Users\\\\ekino\\\\OneDrive - UW\\\\GPR\\\\Results\\\\60\\\\all_parameters\\\\params_{}.csv'.format(id)\n",
    "\n",
    "     # Read both files\n",
    "    res = pd.read_csv(result_file, header=0)\n",
    "    par = pd.read_csv(params_file, header=0)\n",
    "    par.columns = ['param', 'value']\n",
    "\n",
    "    mtgp_mae = np.append(mtgp_mae, res['MAE'][0])\n",
    "    mtgp_rmse = np.append(mtgp_rmse, res['RMSE'][0])\n",
    "    mtgp_mad = np.append(mtgp_mad, res['MAD'][0])\n",
    "    mtgp_mape = np.append(mtgp_mape, res['MAPE'][0])\n",
    "    mtgp_maxape = np.append(mtgp_maxape, res['MAXAPE'][0])\n",
    "    mtgp_tape = np.append(mtgp_tape, res['TAPE'][0])\n",
    "    ses_mae = np.append(ses_mae, res['MAE'][1])\n",
    "    ses_rmse = np.append(ses_rmse, res['RMSE'][1])\n",
    "    ses_mad = np.append(ses_mad, res['MAD'][1])\n",
    "    ses_mape = np.append(ses_mape, res['MAPE'][1])\n",
    "    ses_maxape = np.append(ses_maxape, res['MAXAPE'][1])\n",
    "    ses_tape = np.append(ses_tape, res['TAPE'][1])\n",
    "    holt_mae = np.append(holt_mae, res['MAE'][2])\n",
    "    holt_rmse = np.append(holt_rmse, res['RMSE'][2])\n",
    "    holt_mad = np.append(holt_mad, res['MAD'][2])\n",
    "    holt_mape = np.append(holt_mape, res['MAPE'][2])\n",
    "    holt_maxape = np.append(holt_maxape, res['MAXAPE'][2])\n",
    "    holt_tape = np.append(holt_tape, res['TAPE'][2])\n",
    "    es_mae = np.append(es_mae, res['MAE'][3])\n",
    "    es_rmse = np.append(es_rmse, res['RMSE'][3])\n",
    "    es_mad = np.append(es_mad, res['MAD'][3])\n",
    "    es_mape = np.append(es_mape, res['MAPE'][3])\n",
    "    es_maxape = np.append(es_maxape, res['MAXAPE'][3])\n",
    "    es_tape = np.append(es_tape, res['TAPE'][3])\n",
    "    arima_mae = np.append(arima_mae, res['MAE'][4])\n",
    "    arima_rmse = np.append(arima_rmse, res['RMSE'][4])\n",
    "    arima_mad = np.append(arima_mad, res['MAD'][4])\n",
    "    arima_mape = np.append(arima_mape, res['MAPE'][4])\n",
    "    arima_maxape = np.append(arima_maxape, res['MAXAPE'][4])\n",
    "    arima_tape = np.append(arima_tape, res['TAPE'][4])\n",
    "    sarima_mae = np.append(sarima_mae, res['MAE'][5])\n",
    "    sarima_rmse = np.append(sarima_rmse, res['RMSE'][5])\n",
    "    sarima_mad = np.append(sarima_mad, res['MAD'][5])\n",
    "    sarima_mape = np.append(sarima_mape, res['MAPE'][5])\n",
    "    sarima_maxape = np.append(sarima_maxape, res['MAXAPE'][5])\n",
    "    sarima_tape = np.append(sarima_tape, res['TAPE'][5])\n",
    "    new_ocp = np.append(new_ocp, par[par['param'] == 'new_ocp'].value.astype(float))\n",
    "    init_lengthscale = np.append(init_lengthscale, par[par['param'] == 'init_lengthscale'].value.astype(float))\n",
    "    bic = np.append(bic, par[par['param'] == 'bic'].value.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTempOcpvsError(mtgp_mae, new_ocp, fitline=True, title=r'$\\tau = 1$ hour', xlabel='Temporal occupancy', ylabel='MAE', figsize=(8,6), c='b', marker='o', label='MTGP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=1.3, rc={\"lines.linewidth\": 2.5})\n",
    "plt.figure(figsize=(15, 5))\n",
    "# Set title, write in latex\n",
    "plt.suptitle(r'$\\tau = 1$ hour', fontsize=20)\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.boxplot([mtgp_mae, ses_mae, holt_mae, es_mae, arima_mae, sarima_mae])\n",
    "plt.title('MAE')\n",
    "plt.xticks([1, 2, 3, 4, 5, 6], [r'$\\bf{MTGP}$', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX'])\n",
    "plt.ylim(0, 6)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.boxplot([mtgp_rmse, ses_rmse, holt_rmse, es_rmse, arima_rmse, sarima_rmse])\n",
    "plt.title('RMSE')\n",
    "plt.ylim(0, 6)\n",
    "plt.xticks([1, 2, 3, 4, 5, 6], [r'$\\bf{MTGP}$', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX'])\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.boxplot([mtgp_mad, ses_mad, holt_mad, es_mad, arima_mad, sarima_mad])\n",
    "plt.title('MAD')\n",
    "plt.ylim(0, 4)\n",
    "plt.xticks([1, 2, 3, 4, 5, 6], [r'$\\bf{MTGP}$', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_files = glob.glob('C:\\\\Users\\\\ekino\\\\OneDrive - UW\\\\GPR\\\\Results\\\\30\\\\all_results\\\\results_*.csv')\n",
    "params_files = glob.glob('C:\\\\Users\\\\ekino\\\\OneDrive - UW\\\\GPR\\\\Results\\\\30\\\\all_parameters\\\\params_*.csv')\n",
    "\n",
    "# Loop through each file name and extract unique identifier\n",
    "results_ids = [f.split('_')[2].split('.')[0] for f in results_files]\n",
    "params_ids = [f.split('_')[2].split('.')[0] for f in params_files]\n",
    "\n",
    "mtgp_mae = np.array([])\n",
    "mtgp_rmse = np.array([])\n",
    "mtgp_mad = np.array([])\n",
    "mtgp_mape = np.array([])\n",
    "mtgp_maxape = np.array([])\n",
    "mtgp_tape = np.array([])\n",
    "ses_mae = np.array([])\n",
    "ses_rmse = np.array([])\n",
    "ses_mad = np.array([])\n",
    "ses_mape = np.array([])\n",
    "ses_maxape = np.array([])\n",
    "ses_tape = np.array([])\n",
    "holt_mae = np.array([])\n",
    "holt_rmse = np.array([])\n",
    "holt_mad = np.array([])\n",
    "holt_mape = np.array([])\n",
    "holt_maxape = np.array([])\n",
    "holt_tape = np.array([])\n",
    "es_mae = np.array([])\n",
    "es_rmse = np.array([])\n",
    "es_mad = np.array([])\n",
    "es_mape = np.array([])\n",
    "es_maxape = np.array([])\n",
    "es_tape = np.array([])\n",
    "arima_mae = np.array([])\n",
    "arima_rmse = np.array([])\n",
    "arima_mad = np.array([])\n",
    "arima_mape = np.array([])\n",
    "arima_maxape = np.array([])\n",
    "arima_tape = np.array([])\n",
    "sarima_mae = np.array([])\n",
    "sarima_rmse = np.array([])\n",
    "sarima_mad = np.array([])\n",
    "sarima_mape = np.array([])\n",
    "sarima_maxape = np.array([])\n",
    "sarima_tape = np.array([])\n",
    "new_ocp = np.array([])\n",
    "init_lengthscale = np.array([])\n",
    "bic = np.array([])\n",
    "\n",
    "\n",
    "# Loop through each unique identifier and read corresponding files\n",
    "for id in set(results_ids) & set(params_ids):\n",
    "    result_file = 'C:\\\\Users\\\\ekino\\\\OneDrive - UW\\\\GPR\\\\Results\\\\30\\\\all_results\\\\results_{}.csv'.format(id)\n",
    "    params_file = 'C:\\\\Users\\\\ekino\\\\OneDrive - UW\\\\GPR\\\\Results\\\\30\\\\all_parameters\\\\params_{}.csv'.format(id)\n",
    "\n",
    "     # Read both files\n",
    "    res = pd.read_csv(result_file, header=0)\n",
    "    par = pd.read_csv(params_file, header=0)\n",
    "    par.columns = ['param', 'value']\n",
    "\n",
    "    mtgp_mae = np.append(mtgp_mae, res['MAE'][0])\n",
    "    mtgp_rmse = np.append(mtgp_rmse, res['RMSE'][0])\n",
    "    mtgp_mad = np.append(mtgp_mad, res['MAD'][0])\n",
    "    mtgp_mape = np.append(mtgp_mape, res['MAPE'][0])\n",
    "    mtgp_maxape = np.append(mtgp_maxape, res['MAXAPE'][0])\n",
    "    mtgp_tape = np.append(mtgp_tape, res['TAPE'][0])\n",
    "    ses_mae = np.append(ses_mae, res['MAE'][1])\n",
    "    ses_rmse = np.append(ses_rmse, res['RMSE'][1])\n",
    "    ses_mad = np.append(ses_mad, res['MAD'][1])\n",
    "    ses_mape = np.append(ses_mape, res['MAPE'][1])\n",
    "    ses_maxape = np.append(ses_maxape, res['MAXAPE'][1])\n",
    "    ses_tape = np.append(ses_tape, res['TAPE'][1])\n",
    "    holt_mae = np.append(holt_mae, res['MAE'][2])\n",
    "    holt_rmse = np.append(holt_rmse, res['RMSE'][2])\n",
    "    holt_mad = np.append(holt_mad, res['MAD'][2])\n",
    "    holt_mape = np.append(holt_mape, res['MAPE'][2])\n",
    "    holt_maxape = np.append(holt_maxape, res['MAXAPE'][2])\n",
    "    holt_tape = np.append(holt_tape, res['TAPE'][2])\n",
    "    es_mae = np.append(es_mae, res['MAE'][3])\n",
    "    es_rmse = np.append(es_rmse, res['RMSE'][3])\n",
    "    es_mad = np.append(es_mad, res['MAD'][3])\n",
    "    es_mape = np.append(es_mape, res['MAPE'][3])\n",
    "    es_maxape = np.append(es_maxape, res['MAXAPE'][3])\n",
    "    es_tape = np.append(es_tape, res['TAPE'][3])\n",
    "    arima_mae = np.append(arima_mae, res['MAE'][4])\n",
    "    arima_rmse = np.append(arima_rmse, res['RMSE'][4])\n",
    "    arima_mad = np.append(arima_mad, res['MAD'][4])\n",
    "    arima_mape = np.append(arima_mape, res['MAPE'][4])\n",
    "    arima_maxape = np.append(arima_maxape, res['MAXAPE'][4])\n",
    "    arima_tape = np.append(arima_tape, res['TAPE'][4])\n",
    "    sarima_mae = np.append(sarima_mae, res['MAE'][5])\n",
    "    sarima_rmse = np.append(sarima_rmse, res['RMSE'][5])\n",
    "    sarima_mad = np.append(sarima_mad, res['MAD'][5])\n",
    "    sarima_mape = np.append(sarima_mape, res['MAPE'][5])\n",
    "    sarima_maxape = np.append(sarima_maxape, res['MAXAPE'][5])\n",
    "    sarima_tape = np.append(sarima_tape, res['TAPE'][5])\n",
    "    new_ocp = np.append(new_ocp, par[par['param'] == 'new_ocp'].value.astype(float))\n",
    "    init_lengthscale = np.append(init_lengthscale, par[par['param'] == 'init_lengthscale'].value.astype(float))\n",
    "    bic = np.append(bic, par[par['param'] == 'bic'].value.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTempOcpvsError(mtgp_mae, new_ocp, fitline=True, title=r'$\\tau = 30$ minutes', xlabel='Temporal occupancy', ylabel='MAE', figsize=(8,6), c='b', marker='o', label='MTGP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=1.3, rc={\"lines.linewidth\": 2.5})\n",
    "plt.figure(figsize=(15, 5))\n",
    "# Set title, write in latex\n",
    "plt.suptitle(r'$\\tau = 30$ minutes', fontsize=20)\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.boxplot([mtgp_mae, ses_mae, holt_mae, es_mae, arima_mae, sarima_mae])\n",
    "plt.title('MAE')\n",
    "plt.xticks([1, 2, 3, 4, 5, 6], [r'$\\bf{MTGP}$', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX'])\n",
    "plt.ylim(0, 6)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.boxplot([mtgp_rmse, ses_rmse, holt_rmse, es_rmse, arima_rmse, sarima_rmse])\n",
    "plt.title('RMSE')\n",
    "plt.ylim(0, 6)\n",
    "plt.xticks([1, 2, 3, 4, 5, 6], [r'$\\bf{MTGP}$', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX'])\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.boxplot([mtgp_mad, ses_mad, holt_mad, es_mad, arima_mad, sarima_mad])\n",
    "plt.title('MAD')\n",
    "plt.ylim(0, 4)\n",
    "plt.xticks([1, 2, 3, 4, 5, 6], [r'$\\bf{MTGP}$', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_files = glob.glob('C:\\\\Users\\\\ekino\\\\OneDrive - UW\\\\GPR\\\\Results\\\\15\\\\all_results\\\\results_*.csv')\n",
    "params_files = glob.glob('C:\\\\Users\\\\ekino\\\\OneDrive - UW\\\\GPR\\\\Results\\\\15\\\\all_parameters\\\\params_*.csv')\n",
    "\n",
    "# Loop through each file name and extract unique identifier\n",
    "results_ids = [f.split('_')[2].split('.')[0] for f in results_files]\n",
    "params_ids = [f.split('_')[2].split('.')[0] for f in params_files]\n",
    "\n",
    "mtgp_mae = np.array([])\n",
    "mtgp_rmse = np.array([])\n",
    "mtgp_mad = np.array([])\n",
    "mtgp_mape = np.array([])\n",
    "mtgp_maxape = np.array([])\n",
    "mtgp_tape = np.array([])\n",
    "ses_mae = np.array([])\n",
    "ses_rmse = np.array([])\n",
    "ses_mad = np.array([])\n",
    "ses_mape = np.array([])\n",
    "ses_maxape = np.array([])\n",
    "ses_tape = np.array([])\n",
    "holt_mae = np.array([])\n",
    "holt_rmse = np.array([])\n",
    "holt_mad = np.array([])\n",
    "holt_mape = np.array([])\n",
    "holt_maxape = np.array([])\n",
    "holt_tape = np.array([])\n",
    "es_mae = np.array([])\n",
    "es_rmse = np.array([])\n",
    "es_mad = np.array([])\n",
    "es_mape = np.array([])\n",
    "es_maxape = np.array([])\n",
    "es_tape = np.array([])\n",
    "arima_mae = np.array([])\n",
    "arima_rmse = np.array([])\n",
    "arima_mad = np.array([])\n",
    "arima_mape = np.array([])\n",
    "arima_maxape = np.array([])\n",
    "arima_tape = np.array([])\n",
    "sarima_mae = np.array([])\n",
    "sarima_rmse = np.array([])\n",
    "sarima_mad = np.array([])\n",
    "sarima_mape = np.array([])\n",
    "sarima_maxape = np.array([])\n",
    "sarima_tape = np.array([])\n",
    "new_ocp = np.array([])\n",
    "init_lengthscale = np.array([])\n",
    "bic = np.array([])\n",
    "\n",
    "\n",
    "# Loop through each unique identifier and read corresponding files\n",
    "for id in set(results_ids) & set(params_ids):\n",
    "    result_file = 'C:\\\\Users\\\\ekino\\\\OneDrive - UW\\\\GPR\\\\Results\\\\15\\\\all_results\\\\results_{}.csv'.format(id)\n",
    "    params_file = 'C:\\\\Users\\\\ekino\\\\OneDrive - UW\\\\GPR\\\\Results\\\\15\\\\all_parameters\\\\params_{}.csv'.format(id)\n",
    "\n",
    "     # Read both files\n",
    "    res = pd.read_csv(result_file, header=0)\n",
    "    par = pd.read_csv(params_file, header=0)\n",
    "    par.columns = ['param', 'value']\n",
    "\n",
    "    mtgp_mae = np.append(mtgp_mae, res['MAE'][0])\n",
    "    mtgp_rmse = np.append(mtgp_rmse, res['RMSE'][0])\n",
    "    mtgp_mad = np.append(mtgp_mad, res['MAD'][0])\n",
    "    mtgp_mape = np.append(mtgp_mape, res['MAPE'][0])\n",
    "    mtgp_maxape = np.append(mtgp_maxape, res['MAXAPE'][0])\n",
    "    mtgp_tape = np.append(mtgp_tape, res['TAPE'][0])\n",
    "    ses_mae = np.append(ses_mae, res['MAE'][1])\n",
    "    ses_rmse = np.append(ses_rmse, res['RMSE'][1])\n",
    "    ses_mad = np.append(ses_mad, res['MAD'][1])\n",
    "    ses_mape = np.append(ses_mape, res['MAPE'][1])\n",
    "    ses_maxape = np.append(ses_maxape, res['MAXAPE'][1])\n",
    "    ses_tape = np.append(ses_tape, res['TAPE'][1])\n",
    "    holt_mae = np.append(holt_mae, res['MAE'][2])\n",
    "    holt_rmse = np.append(holt_rmse, res['RMSE'][2])\n",
    "    holt_mad = np.append(holt_mad, res['MAD'][2])\n",
    "    holt_mape = np.append(holt_mape, res['MAPE'][2])\n",
    "    holt_maxape = np.append(holt_maxape, res['MAXAPE'][2])\n",
    "    holt_tape = np.append(holt_tape, res['TAPE'][2])\n",
    "    es_mae = np.append(es_mae, res['MAE'][3])\n",
    "    es_rmse = np.append(es_rmse, res['RMSE'][3])\n",
    "    es_mad = np.append(es_mad, res['MAD'][3])\n",
    "    es_mape = np.append(es_mape, res['MAPE'][3])\n",
    "    es_maxape = np.append(es_maxape, res['MAXAPE'][3])\n",
    "    es_tape = np.append(es_tape, res['TAPE'][3])\n",
    "    arima_mae = np.append(arima_mae, res['MAE'][4])\n",
    "    arima_rmse = np.append(arima_rmse, res['RMSE'][4])\n",
    "    arima_mad = np.append(arima_mad, res['MAD'][4])\n",
    "    arima_mape = np.append(arima_mape, res['MAPE'][4])\n",
    "    arima_maxape = np.append(arima_maxape, res['MAXAPE'][4])\n",
    "    arima_tape = np.append(arima_tape, res['TAPE'][4])\n",
    "    sarima_mae = np.append(sarima_mae, res['MAE'][5])\n",
    "    sarima_rmse = np.append(sarima_rmse, res['RMSE'][5])\n",
    "    sarima_mad = np.append(sarima_mad, res['MAD'][5])\n",
    "    sarima_mape = np.append(sarima_mape, res['MAPE'][5])\n",
    "    sarima_maxape = np.append(sarima_maxape, res['MAXAPE'][5])\n",
    "    sarima_tape = np.append(sarima_tape, res['TAPE'][5])\n",
    "    new_ocp = np.append(new_ocp, par[par['param'] == 'new_ocp'].value.astype(float))\n",
    "    init_lengthscale = np.append(init_lengthscale, par[par['param'] == 'init_lengthscale'].value.astype(float))\n",
    "    bic = np.append(bic, par[par['param'] == 'bic'].value.astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTempOcpvsError(mtgp_mae, new_ocp, fitline=True, title=r'$\\tau = 15$ minutes', xlabel='Temporal occupancy', ylabel='MAE', figsize=(8,6), c='b', marker='o', label='MTGP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=1.3, rc={\"lines.linewidth\": 2.5})\n",
    "plt.figure(figsize=(15, 5))\n",
    "# Set title, write in latex\n",
    "plt.suptitle(r'$\\tau = 15$ minutes', fontsize=20)\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.boxplot([mtgp_mae, ses_mae, holt_mae, es_mae, arima_mae, sarima_mae])\n",
    "plt.title('MAE')\n",
    "plt.xticks([1, 2, 3, 4, 5, 6], [r'$\\bf{MTGP}$', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX'])\n",
    "plt.ylim(0, 6)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.boxplot([mtgp_rmse, ses_rmse, holt_rmse, es_rmse, arima_rmse, sarima_rmse])\n",
    "plt.title('RMSE')\n",
    "plt.ylim(0, 6)\n",
    "plt.xticks([1, 2, 3, 4, 5, 6], [r'$\\bf{MTGP}$', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX'])\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.boxplot([mtgp_mad, ses_mad, holt_mad, es_mad, arima_mad, sarima_mad])\n",
    "plt.title('MAD')\n",
    "plt.ylim(0, 4)\n",
    "plt.xticks([1, 2, 3, 4, 5, 6], [r'$\\bf{MTGP}$', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycle through each file and save results as a numpy array\n",
    "folderpath=\"C:\\\\Users\\\\ekino\\\\OneDrive - UW\\\\GPR\\\\Results\\\\1\\\\all_results\"\n",
    "os.chdir(folderpath)\n",
    "all_file_num=len(glob.glob(\"*.csv\"))\n",
    "print(\"There are\", all_file_num, \"files in the folder\")\n",
    "\n",
    "mtgp_mae = np.array([])\n",
    "mtgp_rmse = np.array([])\n",
    "mtgp_mad = np.array([])\n",
    "mtgp_mape = np.array([])\n",
    "mtgp_maxape = np.array([])\n",
    "mtgp_tape = np.array([])\n",
    "ses_mae = np.array([])\n",
    "ses_rmse = np.array([])\n",
    "ses_mad = np.array([])\n",
    "ses_mape = np.array([])\n",
    "ses_maxape = np.array([])\n",
    "ses_tape = np.array([])\n",
    "holt_mae = np.array([])\n",
    "holt_rmse = np.array([])\n",
    "holt_mad = np.array([])\n",
    "holt_mape = np.array([])\n",
    "holt_maxape = np.array([])\n",
    "holt_tape = np.array([])\n",
    "es_mae = np.array([])\n",
    "es_rmse = np.array([])\n",
    "es_mad = np.array([])\n",
    "es_mape = np.array([])\n",
    "es_maxape = np.array([])\n",
    "es_tape = np.array([])\n",
    "arima_mae = np.array([])\n",
    "arima_rmse = np.array([])\n",
    "arima_mad = np.array([])\n",
    "arima_mape = np.array([])\n",
    "arima_maxape = np.array([])\n",
    "arima_tape = np.array([])\n",
    "sarima_mae = np.array([])\n",
    "sarima_rmse = np.array([])\n",
    "sarima_mad = np.array([])\n",
    "sarima_mape = np.array([])\n",
    "sarima_maxape = np.array([])\n",
    "sarima_tape = np.array([])\n",
    "\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    res = pd.read_csv(file, header=0)\n",
    "    # Store each metric in a numpy array\n",
    "    mtgp_mae = np.append(mtgp_mae, res['MAE'][0])\n",
    "    mtgp_rmse = np.append(mtgp_rmse, res['RMSE'][0])\n",
    "    mtgp_mad = np.append(mtgp_mad, res['MAD'][0])\n",
    "    mtgp_mape = np.append(mtgp_mape, res['MAPE'][0])\n",
    "    mtgp_maxape = np.append(mtgp_maxape, res['MAXAPE'][0])\n",
    "    mtgp_tape = np.append(mtgp_tape, res['TAPE'][0])\n",
    "    ses_mae = np.append(ses_mae, res['MAE'][1])\n",
    "    ses_rmse = np.append(ses_rmse, res['RMSE'][1])\n",
    "    ses_mad = np.append(ses_mad, res['MAD'][1])\n",
    "    ses_mape = np.append(ses_mape, res['MAPE'][1])\n",
    "    ses_maxape = np.append(ses_maxape, res['MAXAPE'][1])\n",
    "    ses_tape = np.append(ses_tape, res['TAPE'][1])\n",
    "    holt_mae = np.append(holt_mae, res['MAE'][2])\n",
    "    holt_rmse = np.append(holt_rmse, res['RMSE'][2])\n",
    "    holt_mad = np.append(holt_mad, res['MAD'][2])\n",
    "    holt_mape = np.append(holt_mape, res['MAPE'][2])\n",
    "    holt_maxape = np.append(holt_maxape, res['MAXAPE'][2])\n",
    "    holt_tape = np.append(holt_tape, res['TAPE'][2])\n",
    "    es_mae = np.append(es_mae, res['MAE'][3])\n",
    "    es_rmse = np.append(es_rmse, res['RMSE'][3])\n",
    "    es_mad = np.append(es_mad, res['MAD'][3])\n",
    "    es_mape = np.append(es_mape, res['MAPE'][3])\n",
    "    es_maxape = np.append(es_maxape, res['MAXAPE'][3])\n",
    "    es_tape = np.append(es_tape, res['TAPE'][3])\n",
    "    arima_mae = np.append(arima_mae, res['MAE'][4])\n",
    "    arima_rmse = np.append(arima_rmse, res['RMSE'][4])\n",
    "    arima_mad = np.append(arima_mad, res['MAD'][4])\n",
    "    arima_mape = np.append(arima_mape, res['MAPE'][4])\n",
    "    arima_maxape = np.append(arima_maxape, res['MAXAPE'][4])\n",
    "    arima_tape = np.append(arima_tape, res['TAPE'][4])\n",
    "    sarima_mae = np.append(sarima_mae, res['MAE'][5])\n",
    "    sarima_rmse = np.append(sarima_rmse, res['RMSE'][5])\n",
    "    sarima_mad = np.append(sarima_mad, res['MAD'][5])\n",
    "    sarima_mape = np.append(sarima_mape, res['MAPE'][5])\n",
    "    sarima_maxape = np.append(sarima_maxape, res['MAXAPE'][5])\n",
    "    sarima_tape = np.append(sarima_tape, res['TAPE'][5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=1.3, rc={\"lines.linewidth\": 2.5})\n",
    "plt.figure(figsize=(15, 5))\n",
    "# Set title, write in latex\n",
    "plt.suptitle(r'$\\tau = 1$ minute', fontsize=20)\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.boxplot([mtgp_mae, ses_mae, holt_mae, es_mae, arima_mae, sarima_mae])\n",
    "plt.title('MAE')\n",
    "plt.xticks([1, 2, 3, 4, 5, 6], [r'$\\bf{MTGP}$', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX'])\n",
    "plt.ylim(0, 6)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.boxplot([mtgp_rmse, ses_rmse, holt_rmse, es_rmse, arima_rmse, sarima_rmse])\n",
    "plt.title('RMSE')\n",
    "plt.ylim(0, 6)\n",
    "plt.xticks([1, 2, 3, 4, 5, 6], [r'$\\bf{MTGP}$', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX'])\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.boxplot([mtgp_mad, ses_mad, holt_mad, es_mad, arima_mad, sarima_mad])\n",
    "plt.title('MAD')\n",
    "plt.ylim(0, 4)\n",
    "plt.xticks([1, 2, 3, 4, 5, 6], [r'$\\bf{MTGP}$', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycle through each file and save results as a numpy array\n",
    "folderpath=\"C:\\\\Users\\\\ekino\\\\OneDrive - UW\\\\GPR\\\\Results\\\\10080\\\\all_skmob_metrics\"\n",
    "os.chdir(folderpath)\n",
    "all_file_num=len(glob.glob(\"*.csv\"))\n",
    "print(\"There are\", all_file_num, \"files in the folder\")\n",
    "\n",
    "mtgp_rec = np.array([])\n",
    "mtgp_freq = np.array([])\n",
    "mtgp_no_loc = np.array([])\n",
    "mtgp_k_rg = np.array([])\n",
    "mtgp_spat_burst = np.array([])\n",
    "mtgp_rand_entr = np.array([])\n",
    "mtgp_real_entr = np.array([])\n",
    "mtgp_uncorr_entr = np.array([])\n",
    "mtgp_mae = np.array([])\n",
    "ses_rec = np.array([])\n",
    "ses_freq = np.array([])\n",
    "ses_no_loc = np.array([])\n",
    "ses_k_rg = np.array([])\n",
    "ses_spat_burst = np.array([])\n",
    "ses_rand_entr = np.array([])\n",
    "ses_real_entr = np.array([])\n",
    "ses_uncorr_entr = np.array([])\n",
    "ses_mae = np.array([])\n",
    "holt_rec = np.array([])\n",
    "holt_freq = np.array([])\n",
    "holt_no_loc = np.array([])\n",
    "holt_k_rg = np.array([])\n",
    "holt_spat_burst = np.array([])\n",
    "holt_rand_entr = np.array([])\n",
    "holt_real_entr = np.array([])\n",
    "holt_uncorr_entr = np.array([])\n",
    "holt_mae = np.array([])\n",
    "es_rec = np.array([])\n",
    "es_freq = np.array([])\n",
    "es_no_loc = np.array([])\n",
    "es_k_rg = np.array([])\n",
    "es_spat_burst = np.array([])\n",
    "es_rand_entr = np.array([])\n",
    "es_real_entr = np.array([])\n",
    "es_uncorr_entr = np.array([])\n",
    "es_mae = np.array([])\n",
    "arima_rec = np.array([])\n",
    "arima_freq = np.array([])\n",
    "arima_no_loc = np.array([])\n",
    "arima_k_rg = np.array([])\n",
    "arima_spat_burst = np.array([])\n",
    "arima_rand_entr = np.array([])\n",
    "arima_real_entr = np.array([])\n",
    "arima_uncorr_entr = np.array([])\n",
    "arima_mae = np.array([])\n",
    "sarima_rec = np.array([])\n",
    "sarima_freq = np.array([])\n",
    "sarima_no_loc = np.array([])\n",
    "sarima_k_rg = np.array([])\n",
    "sarima_spat_burst = np.array([])\n",
    "sarima_rand_entr = np.array([])\n",
    "sarima_real_entr = np.array([])\n",
    "sarima_uncorr_entr = np.array([])\n",
    "sarima_mae = np.array([])\n",
    "li_rec = np.array([])\n",
    "li_freq = np.array([])\n",
    "li_no_loc = np.array([])\n",
    "li_k_rg = np.array([])\n",
    "li_spat_burst = np.array([])\n",
    "li_rand_entr = np.array([])\n",
    "li_real_entr = np.array([])\n",
    "li_uncorr_entr = np.array([])\n",
    "li_mae = np.array([])\n",
    "\n",
    "\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    res = pd.read_csv(file, header=0)\n",
    "    # Store each metric in a numpy array\n",
    "    mtgp_rec = np.append(mtgp_rec, res['recency'][0])\n",
    "    mtgp_freq = np.append(mtgp_freq, res['freq_rank'][0])\n",
    "    mtgp_no_loc = np.append(mtgp_no_loc, res['no_loc_error'][0])\n",
    "    mtgp_k_rg = np.append(mtgp_k_rg, res['k_rg_error'][0])\n",
    "    mtgp_spat_burst = np.append(mtgp_spat_burst, res['spat_burst_error'][0])\n",
    "    mtgp_rand_entr = np.append(mtgp_rand_entr, res['rand_entr_error'][0])\n",
    "    mtgp_real_entr = np.append(mtgp_real_entr, res['real_entr_error'][0])\n",
    "    mtgp_uncorr_entr = np.append(mtgp_uncorr_entr, res['uncorr_entr_error'][0])\n",
    "    mtgp_mae = np.append(mtgp_mae, res['mae'][0])\n",
    "    ses_rec = np.append(ses_rec, res['recency'][1])\n",
    "    ses_freq = np.append(ses_freq, res['freq_rank'][1])\n",
    "    ses_no_loc = np.append(ses_no_loc, res['no_loc_error'][1])\n",
    "    ses_k_rg = np.append(ses_k_rg, res['k_rg_error'][1])\n",
    "    ses_spat_burst = np.append(ses_spat_burst, res['spat_burst_error'][1])\n",
    "    ses_rand_entr = np.append(ses_rand_entr, res['rand_entr_error'][1])\n",
    "    ses_real_entr = np.append(ses_real_entr, res['real_entr_error'][1])\n",
    "    ses_uncorr_entr = np.append(ses_uncorr_entr, res['uncorr_entr_error'][1])\n",
    "    ses_mae = np.append(ses_mae, res['mae'][1])\n",
    "    holt_rec = np.append(holt_rec, res['recency'][2])\n",
    "    holt_freq = np.append(holt_freq, res['freq_rank'][2])\n",
    "    holt_no_loc = np.append(holt_no_loc, res['no_loc_error'][2])\n",
    "    holt_k_rg = np.append(holt_k_rg, res['k_rg_error'][2])\n",
    "    holt_spat_burst = np.append(holt_spat_burst, res['spat_burst_error'][2])\n",
    "    holt_rand_entr = np.append(holt_rand_entr, res['rand_entr_error'][2])\n",
    "    holt_real_entr = np.append(holt_real_entr, res['real_entr_error'][2])\n",
    "    holt_uncorr_entr = np.append(holt_uncorr_entr, res['uncorr_entr_error'][2])\n",
    "    holt_mae = np.append(holt_mae, res['mae'][2])\n",
    "    es_rec = np.append(es_rec, res['recency'][3])\n",
    "    es_freq = np.append(es_freq, res['freq_rank'][3])\n",
    "    es_no_loc = np.append(es_no_loc, res['no_loc_error'][3])\n",
    "    es_k_rg = np.append(es_k_rg, res['k_rg_error'][3])\n",
    "    es_spat_burst = np.append(es_spat_burst, res['spat_burst_error'][3])\n",
    "    es_rand_entr = np.append(es_rand_entr, res['rand_entr_error'][3])\n",
    "    es_real_entr = np.append(es_real_entr, res['real_entr_error'][3])\n",
    "    es_uncorr_entr = np.append(es_uncorr_entr, res['uncorr_entr_error'][3])\n",
    "    es_mae = np.append(es_mae, res['mae'][3])\n",
    "    arima_rec = np.append(arima_rec, res['recency'][4])\n",
    "    arima_freq = np.append(arima_freq, res['freq_rank'][4])\n",
    "    arima_no_loc = np.append(arima_no_loc, res['no_loc_error'][4])\n",
    "    arima_k_rg = np.append(arima_k_rg, res['k_rg_error'][4])\n",
    "    arima_spat_burst = np.append(arima_spat_burst, res['spat_burst_error'][4])\n",
    "    arima_rand_entr = np.append(arima_rand_entr, res['rand_entr_error'][4])\n",
    "    arima_real_entr = np.append(arima_real_entr, res['real_entr_error'][4])\n",
    "    arima_uncorr_entr = np.append(arima_uncorr_entr, res['uncorr_entr_error'][4])\n",
    "    arima_mae = np.append(arima_mae, res['mae'][4])\n",
    "    sarima_rec = np.append(sarima_rec, res['recency'][5])\n",
    "    sarima_freq = np.append(sarima_freq, res['freq_rank'][5])\n",
    "    sarima_no_loc = np.append(sarima_no_loc, res['no_loc_error'][5])\n",
    "    sarima_k_rg = np.append(sarima_k_rg, res['k_rg_error'][5])\n",
    "    sarima_spat_burst = np.append(sarima_spat_burst, res['spat_burst_error'][5])\n",
    "    sarima_rand_entr = np.append(sarima_rand_entr, res['rand_entr_error'][5])\n",
    "    sarima_real_entr = np.append(sarima_real_entr, res['real_entr_error'][5])\n",
    "    sarima_uncorr_entr = np.append(sarima_uncorr_entr, res['uncorr_entr_error'][5])\n",
    "    sarima_mae = np.append(sarima_mae, res['mae'][5])\n",
    "    li_rec = np.append(li_rec, res['recency'][6])\n",
    "    li_freq = np.append(li_freq, res['freq_rank'][6])\n",
    "    li_no_loc = np.append(li_no_loc, res['no_loc_error'][6])\n",
    "    li_k_rg = np.append(li_k_rg, res['k_rg_error'][6])\n",
    "    li_spat_burst = np.append(li_spat_burst, res['spat_burst_error'][6])\n",
    "    li_rand_entr = np.append(li_rand_entr, res['rand_entr_error'][6])\n",
    "    li_real_entr = np.append(li_real_entr, res['real_entr_error'][6])\n",
    "    li_uncorr_entr = np.append(li_uncorr_entr, res['uncorr_entr_error'][6])\n",
    "    li_mae = np.append(li_mae, res['mae'][6])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all metrics in the same figure (boxplots)\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=1.3, rc={\"lines.linewidth\": 2.5})\n",
    "plt.figure(figsize=(15, 5))\n",
    "# Set title, write in latex\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.boxplot([mtgp_rec, ses_rec, holt_rec, es_rec, arima_rec, sarima_rec, li_rec], labels=['MTGP', 'SES', 'Holt', 'ES', r'$\\bf{ARIMA}$', 'SARIMAX', 'LI'])\n",
    "plt.title('Recency Accuracy')\n",
    "plt.ylim(0, 0.10)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot([mtgp_freq, ses_freq, holt_freq, es_freq, arima_freq, sarima_freq, li_freq], labels=[r'$\\bf{MTGP}$', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX', 'LI'])\n",
    "plt.title('Frequency Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the rest of the metrics in the same subplots\n",
    "# Three rows, two columns\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(3, 2, 1)\n",
    "plt.boxplot([mtgp_no_loc, ses_no_loc, holt_no_loc, es_no_loc, arima_no_loc, sarima_no_loc, li_no_loc], labels=['MTGP', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX', 'LI'])\n",
    "plt.title('Number of Significant Locations Error')\n",
    "\n",
    "plt.subplot(3, 2, 2)\n",
    "plt.ylim(-10, 10)\n",
    "plt.boxplot([mtgp_k_rg, ses_k_rg, holt_k_rg, es_k_rg, arima_k_rg, sarima_k_rg, li_k_rg], labels=['MTGP', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX', 'LI'])\n",
    "plt.title('Radius of Gyration Error')\n",
    "\n",
    "plt.subplot(3, 2, 3)\n",
    "plt.boxplot([mtgp_spat_burst, ses_spat_burst, holt_spat_burst, es_spat_burst, arima_spat_burst, sarima_spat_burst, li_spat_burst], labels=['MTGP', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX', 'LI'])\n",
    "plt.title('Spatial Burstiness Error')\n",
    "\n",
    "plt.subplot(3, 2, 4)\n",
    "plt.boxplot([mtgp_rand_entr, ses_rand_entr, holt_rand_entr, es_rand_entr, arima_rand_entr, sarima_rand_entr, li_rand_entr], labels=['MTGP', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX', 'LI'])\n",
    "plt.title('Random Entropy Error')\n",
    "\n",
    "plt.subplot(3, 2, 5)\n",
    "plt.boxplot([mtgp_real_entr, ses_real_entr, holt_real_entr, es_real_entr, arima_real_entr, sarima_real_entr, li_real_entr], labels=['MTGP', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX', 'LI'])\n",
    "plt.title('Real Entropy Error')\n",
    "\n",
    "plt.subplot(3, 2, 6)\n",
    "plt.boxplot([mtgp_uncorr_entr, ses_uncorr_entr, holt_uncorr_entr, es_uncorr_entr, arima_uncorr_entr, sarima_uncorr_entr, li_uncorr_entr], labels=['MTGP', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX', 'LI'])\n",
    "plt.title('Uncorrelated Entropy Error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the average value of the metrics for each method\n",
    "avg_rec = np.array([np.mean(mtgp_rec), np.mean(ses_rec), np.mean(holt_rec), np.mean(es_rec), np.mean(arima_rec), np.mean(sarima_rec), np.mean(li_rec)])\n",
    "avg_freq = np.array([np.mean(mtgp_freq), np.mean(ses_freq), np.mean(holt_freq), np.mean(es_freq), np.mean(arima_freq), np.mean(sarima_freq), np.mean(li_freq)])\n",
    "avg_no_loc = np.array([np.mean(mtgp_no_loc), np.mean(ses_no_loc), np.mean(holt_no_loc), np.mean(es_no_loc), np.mean(arima_no_loc), np.mean(sarima_no_loc), np.mean(li_no_loc)])\n",
    "avg_k_rg = np.array([np.mean(mtgp_k_rg), np.mean(ses_k_rg), np.mean(holt_k_rg), np.mean(es_k_rg), np.mean(arima_k_rg), np.mean(sarima_k_rg), np.mean(li_k_rg)])\n",
    "avg_spat_burst = np.array([np.mean(mtgp_spat_burst), np.mean(ses_spat_burst), np.mean(holt_spat_burst), np.mean(es_spat_burst), np.mean(arima_spat_burst), np.mean(sarima_spat_burst), np.mean(li_spat_burst)])\n",
    "avg_rand_entr = np.array([np.mean(mtgp_rand_entr), np.mean(ses_rand_entr), np.mean(holt_rand_entr), np.mean(es_rand_entr), np.mean(arima_rand_entr), np.mean(sarima_rand_entr), np.mean(li_rand_entr)])\n",
    "avg_real_entr = np.array([np.mean(mtgp_real_entr), np.mean(ses_real_entr), np.mean(holt_real_entr), np.mean(es_real_entr), np.mean(arima_real_entr), np.mean(sarima_real_entr), np.mean(li_real_entr)])\n",
    "avg_uncorr_entr = np.array([np.mean(mtgp_uncorr_entr), np.mean(ses_uncorr_entr), np.mean(holt_uncorr_entr), np.mean(es_uncorr_entr), np.mean(arima_uncorr_entr), np.mean(sarima_uncorr_entr), np.mean(li_uncorr_entr)])\n",
    "\n",
    "# Get the standard deviation of the metrics for each method\n",
    "std_rec = np.array([np.std(mtgp_rec), np.std(ses_rec), np.std(holt_rec), np.std(es_rec), np.std(arima_rec), np.std(sarima_rec), np.std(li_rec)])\n",
    "std_freq = np.array([np.std(mtgp_freq), np.std(ses_freq), np.std(holt_freq), np.std(es_freq), np.std(arima_freq), np.std(sarima_freq), np.std(li_freq)])\n",
    "std_no_loc = np.array([np.std(mtgp_no_loc), np.std(ses_no_loc), np.std(holt_no_loc), np.std(es_no_loc), np.std(arima_no_loc), np.std(sarima_no_loc), np.std(li_no_loc)])\n",
    "std_k_rg = np.array([np.std(mtgp_k_rg), np.std(ses_k_rg), np.std(holt_k_rg), np.std(es_k_rg), np.std(arima_k_rg), np.std(sarima_k_rg), np.std(li_k_rg)])\n",
    "std_spat_burst = np.array([np.std(mtgp_spat_burst), np.std(ses_spat_burst), np.std(holt_spat_burst), np.std(es_spat_burst), np.std(arima_spat_burst), np.std(sarima_spat_burst), np.std(li_spat_burst)])\n",
    "std_rand_entr = np.array([np.std(mtgp_rand_entr), np.std(ses_rand_entr), np.std(holt_rand_entr), np.std(es_rand_entr), np.std(arima_rand_entr), np.std(sarima_rand_entr), np.std(li_rand_entr)])\n",
    "std_real_entr = np.array([np.std(mtgp_real_entr), np.std(ses_real_entr), np.std(holt_real_entr), np.std(es_real_entr), np.std(arima_real_entr), np.std(sarima_real_entr), np.std(li_real_entr)])\n",
    "std_uncorr_entr = np.array([np.std(mtgp_uncorr_entr), np.std(ses_uncorr_entr), np.std(holt_uncorr_entr), np.std(es_uncorr_entr), np.std(arima_uncorr_entr), np.std(sarima_uncorr_entr), np.std(li_uncorr_entr)])\n",
    "\n",
    "# Plot the average values of the metrics for each method\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(3, 2, 1)\n",
    "plt.bar(['MTGP', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX', 'LI'], avg_rec, yerr=std_rec)\n",
    "plt.title('Recency ranking accuracy')\n",
    "plt.subplot(3, 2, 2)\n",
    "plt.bar(['MTGP', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX', 'LI'], avg_freq, yerr=std_freq)\n",
    "plt.title('Frequency ranking accuracy')\n",
    "plt.subplot(3, 2, 3)\n",
    "plt.bar(['MTGP', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX', 'LI'], avg_no_loc, yerr=std_no_loc)\n",
    "plt.title('Number of locations error')\n",
    "plt.subplot(3, 2, 4)\n",
    "plt.bar(['MTGP', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX', 'LI'], avg_k_rg, yerr=std_k_rg)\n",
    "plt.title('Radius of gyration error')\n",
    "plt.subplot(3, 2, 5)\n",
    "plt.bar(['MTGP', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX', 'LI'], avg_real_entr, yerr=std_real_entr)\n",
    "plt.title('Real entropy error')\n",
    "plt.subplot(3, 2, 6)\n",
    "plt.bar(['MTGP', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX', 'LI'], avg_rand_entr, yerr=std_rand_entr)\n",
    "plt.title('Random entropy error')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put averages into a dataframe\n",
    "df_10080_skmob = pd.DataFrame({'Method': ['MTGP', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX', 'LI'],\n",
    "                     'Recency ranking accuracy': avg_rec,\n",
    "                        'Frequency ranking accuracy': avg_freq,\n",
    "                        'Number of locations error': avg_no_loc,\n",
    "                        'Radius of gyration error': avg_k_rg,\n",
    "                        'Real entropy error': avg_real_entr,\n",
    "                        'Random entropy error': avg_rand_entr,\n",
    "                        'Uncorrelated entropy error': avg_uncorr_entr})\n",
    "\n",
    "df_10080_skmob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycle through each file and save results as a numpy array\n",
    "folderpath=\"C:\\\\Users\\\\ekino\\\\OneDrive - UW\\\\GPR\\\\Results\\\\1440\\\\all_skmob_metrics\"\n",
    "os.chdir(folderpath)\n",
    "all_file_num=len(glob.glob(\"*.csv\"))\n",
    "print(\"There are\", all_file_num, \"files in the folder\")\n",
    "\n",
    "mtgp_rec = np.array([])\n",
    "mtgp_freq = np.array([])\n",
    "mtgp_no_loc = np.array([])\n",
    "mtgp_k_rg = np.array([])\n",
    "mtgp_spat_burst = np.array([])\n",
    "mtgp_rand_entr = np.array([])\n",
    "mtgp_real_entr = np.array([])\n",
    "mtgp_uncorr_entr = np.array([])\n",
    "mtgp_mae = np.array([])\n",
    "ses_rec = np.array([])\n",
    "ses_freq = np.array([])\n",
    "ses_no_loc = np.array([])\n",
    "ses_k_rg = np.array([])\n",
    "ses_spat_burst = np.array([])\n",
    "ses_rand_entr = np.array([])\n",
    "ses_real_entr = np.array([])\n",
    "ses_uncorr_entr = np.array([])\n",
    "ses_mae = np.array([])\n",
    "holt_rec = np.array([])\n",
    "holt_freq = np.array([])\n",
    "holt_no_loc = np.array([])\n",
    "holt_k_rg = np.array([])\n",
    "holt_spat_burst = np.array([])\n",
    "holt_rand_entr = np.array([])\n",
    "holt_real_entr = np.array([])\n",
    "holt_uncorr_entr = np.array([])\n",
    "holt_mae = np.array([])\n",
    "es_rec = np.array([])\n",
    "es_freq = np.array([])\n",
    "es_no_loc = np.array([])\n",
    "es_k_rg = np.array([])\n",
    "es_spat_burst = np.array([])\n",
    "es_rand_entr = np.array([])\n",
    "es_real_entr = np.array([])\n",
    "es_uncorr_entr = np.array([])\n",
    "es_mae = np.array([])\n",
    "arima_rec = np.array([])\n",
    "arima_freq = np.array([])\n",
    "arima_no_loc = np.array([])\n",
    "arima_k_rg = np.array([])\n",
    "arima_spat_burst = np.array([])\n",
    "arima_rand_entr = np.array([])\n",
    "arima_real_entr = np.array([])\n",
    "arima_uncorr_entr = np.array([])\n",
    "arima_mae = np.array([])\n",
    "sarima_rec = np.array([])\n",
    "sarima_freq = np.array([])\n",
    "sarima_no_loc = np.array([])\n",
    "sarima_k_rg = np.array([])\n",
    "sarima_spat_burst = np.array([])\n",
    "sarima_rand_entr = np.array([])\n",
    "sarima_real_entr = np.array([])\n",
    "sarima_uncorr_entr = np.array([])\n",
    "sarima_mae = np.array([])\n",
    "li_rec = np.array([])\n",
    "li_freq = np.array([])\n",
    "li_no_loc = np.array([])\n",
    "li_k_rg = np.array([])\n",
    "li_spat_burst = np.array([])\n",
    "li_rand_entr = np.array([])\n",
    "li_real_entr = np.array([])\n",
    "li_uncorr_entr = np.array([])\n",
    "li_mae = np.array([])\n",
    "\n",
    "\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    res = pd.read_csv(file, header=0)\n",
    "    # Store each metric in a numpy array\n",
    "    mtgp_rec = np.append(mtgp_rec, res['recency'][0])\n",
    "    mtgp_freq = np.append(mtgp_freq, res['freq_rank'][0])\n",
    "    mtgp_no_loc = np.append(mtgp_no_loc, res['no_loc_error'][0])\n",
    "    mtgp_k_rg = np.append(mtgp_k_rg, res['k_rg_error'][0])\n",
    "    mtgp_spat_burst = np.append(mtgp_spat_burst, res['spat_burst_error'][0])\n",
    "    mtgp_rand_entr = np.append(mtgp_rand_entr, res['rand_entr_error'][0])\n",
    "    mtgp_real_entr = np.append(mtgp_real_entr, res['real_entr_error'][0])\n",
    "    mtgp_uncorr_entr = np.append(mtgp_uncorr_entr, res['uncorr_entr_error'][0])\n",
    "    mtgp_mae = np.append(mtgp_mae, res['mae'][0])\n",
    "    ses_rec = np.append(ses_rec, res['recency'][1])\n",
    "    ses_freq = np.append(ses_freq, res['freq_rank'][1])\n",
    "    ses_no_loc = np.append(ses_no_loc, res['no_loc_error'][1])\n",
    "    ses_k_rg = np.append(ses_k_rg, res['k_rg_error'][1])\n",
    "    ses_spat_burst = np.append(ses_spat_burst, res['spat_burst_error'][1])\n",
    "    ses_rand_entr = np.append(ses_rand_entr, res['rand_entr_error'][1])\n",
    "    ses_real_entr = np.append(ses_real_entr, res['real_entr_error'][1])\n",
    "    ses_uncorr_entr = np.append(ses_uncorr_entr, res['uncorr_entr_error'][1])\n",
    "    ses_mae = np.append(ses_mae, res['mae'][1])\n",
    "    holt_rec = np.append(holt_rec, res['recency'][2])\n",
    "    holt_freq = np.append(holt_freq, res['freq_rank'][2])\n",
    "    holt_no_loc = np.append(holt_no_loc, res['no_loc_error'][2])\n",
    "    holt_k_rg = np.append(holt_k_rg, res['k_rg_error'][2])\n",
    "    holt_spat_burst = np.append(holt_spat_burst, res['spat_burst_error'][2])\n",
    "    holt_rand_entr = np.append(holt_rand_entr, res['rand_entr_error'][2])\n",
    "    holt_real_entr = np.append(holt_real_entr, res['real_entr_error'][2])\n",
    "    holt_uncorr_entr = np.append(holt_uncorr_entr, res['uncorr_entr_error'][2])\n",
    "    holt_mae = np.append(holt_mae, res['mae'][2])\n",
    "    es_rec = np.append(es_rec, res['recency'][3])\n",
    "    es_freq = np.append(es_freq, res['freq_rank'][3])\n",
    "    es_no_loc = np.append(es_no_loc, res['no_loc_error'][3])\n",
    "    es_k_rg = np.append(es_k_rg, res['k_rg_error'][3])\n",
    "    es_spat_burst = np.append(es_spat_burst, res['spat_burst_error'][3])\n",
    "    es_rand_entr = np.append(es_rand_entr, res['rand_entr_error'][3])\n",
    "    es_real_entr = np.append(es_real_entr, res['real_entr_error'][3])\n",
    "    es_uncorr_entr = np.append(es_uncorr_entr, res['uncorr_entr_error'][3])\n",
    "    es_mae = np.append(es_mae, res['mae'][3])\n",
    "    arima_rec = np.append(arima_rec, res['recency'][4])\n",
    "    arima_freq = np.append(arima_freq, res['freq_rank'][4])\n",
    "    arima_no_loc = np.append(arima_no_loc, res['no_loc_error'][4])\n",
    "    arima_k_rg = np.append(arima_k_rg, res['k_rg_error'][4])\n",
    "    arima_spat_burst = np.append(arima_spat_burst, res['spat_burst_error'][4])\n",
    "    arima_rand_entr = np.append(arima_rand_entr, res['rand_entr_error'][4])\n",
    "    arima_real_entr = np.append(arima_real_entr, res['real_entr_error'][4])\n",
    "    arima_uncorr_entr = np.append(arima_uncorr_entr, res['uncorr_entr_error'][4])\n",
    "    arima_mae = np.append(arima_mae, res['mae'][4])\n",
    "    sarima_rec = np.append(sarima_rec, res['recency'][5])\n",
    "    sarima_freq = np.append(sarima_freq, res['freq_rank'][5])\n",
    "    sarima_no_loc = np.append(sarima_no_loc, res['no_loc_error'][5])\n",
    "    sarima_k_rg = np.append(sarima_k_rg, res['k_rg_error'][5])\n",
    "    sarima_spat_burst = np.append(sarima_spat_burst, res['spat_burst_error'][5])\n",
    "    sarima_rand_entr = np.append(sarima_rand_entr, res['rand_entr_error'][5])\n",
    "    sarima_real_entr = np.append(sarima_real_entr, res['real_entr_error'][5])\n",
    "    sarima_uncorr_entr = np.append(sarima_uncorr_entr, res['uncorr_entr_error'][5])\n",
    "    sarima_mae = np.append(sarima_mae, res['mae'][5])\n",
    "    li_rec = np.append(li_rec, res['recency'][6])\n",
    "    li_freq = np.append(li_freq, res['freq_rank'][6])\n",
    "    li_no_loc = np.append(li_no_loc, res['no_loc_error'][6])\n",
    "    li_k_rg = np.append(li_k_rg, res['k_rg_error'][6])\n",
    "    li_spat_burst = np.append(li_spat_burst, res['spat_burst_error'][6])\n",
    "    li_rand_entr = np.append(li_rand_entr, res['rand_entr_error'][6])\n",
    "    li_real_entr = np.append(li_real_entr, res['real_entr_error'][6])\n",
    "    li_uncorr_entr = np.append(li_uncorr_entr, res['uncorr_entr_error'][6])\n",
    "    li_mae = np.append(li_mae, res['mae'][6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the average value of the metrics for each method\n",
    "avg_rec = np.array([np.mean(mtgp_rec), np.mean(ses_rec), np.mean(holt_rec), np.mean(es_rec), np.mean(arima_rec), np.mean(sarima_rec), np.mean(li_rec)])\n",
    "avg_freq = np.array([np.mean(mtgp_freq), np.mean(ses_freq), np.mean(holt_freq), np.mean(es_freq), np.mean(arima_freq), np.mean(sarima_freq), np.mean(li_freq)])\n",
    "avg_no_loc = np.array([np.mean(mtgp_no_loc), np.mean(ses_no_loc), np.mean(holt_no_loc), np.mean(es_no_loc), np.mean(arima_no_loc), np.mean(sarima_no_loc), np.mean(li_no_loc)])\n",
    "avg_k_rg = np.array([np.mean(mtgp_k_rg), np.mean(ses_k_rg), np.mean(holt_k_rg), np.mean(es_k_rg), np.mean(arima_k_rg), np.mean(sarima_k_rg), np.mean(li_k_rg)])\n",
    "avg_spat_burst = np.array([np.mean(mtgp_spat_burst), np.mean(ses_spat_burst), np.mean(holt_spat_burst), np.mean(es_spat_burst), np.mean(arima_spat_burst), np.mean(sarima_spat_burst), np.mean(li_spat_burst)])\n",
    "avg_rand_entr = np.array([np.mean(mtgp_rand_entr), np.mean(ses_rand_entr), np.mean(holt_rand_entr), np.mean(es_rand_entr), np.mean(arima_rand_entr), np.mean(sarima_rand_entr), np.mean(li_rand_entr)])\n",
    "avg_real_entr = np.array([np.mean(mtgp_real_entr), np.mean(ses_real_entr), np.mean(holt_real_entr), np.mean(es_real_entr), np.mean(arima_real_entr), np.mean(sarima_real_entr), np.mean(li_real_entr)])\n",
    "avg_uncorr_entr = np.array([np.mean(mtgp_uncorr_entr), np.mean(ses_uncorr_entr), np.mean(holt_uncorr_entr), np.mean(es_uncorr_entr), np.mean(arima_uncorr_entr), np.mean(sarima_uncorr_entr), np.mean(li_uncorr_entr)])\n",
    "\n",
    "# Get the standard deviation of the metrics for each method\n",
    "std_rec = np.array([np.std(mtgp_rec), np.std(ses_rec), np.std(holt_rec), np.std(es_rec), np.std(arima_rec), np.std(sarima_rec), np.std(li_rec)])\n",
    "std_freq = np.array([np.std(mtgp_freq), np.std(ses_freq), np.std(holt_freq), np.std(es_freq), np.std(arima_freq), np.std(sarima_freq), np.std(li_freq)])\n",
    "std_no_loc = np.array([np.std(mtgp_no_loc), np.std(ses_no_loc), np.std(holt_no_loc), np.std(es_no_loc), np.std(arima_no_loc), np.std(sarima_no_loc), np.std(li_no_loc)])\n",
    "std_k_rg = np.array([np.std(mtgp_k_rg), np.std(ses_k_rg), np.std(holt_k_rg), np.std(es_k_rg), np.std(arima_k_rg), np.std(sarima_k_rg), np.std(li_k_rg)])\n",
    "std_spat_burst = np.array([np.std(mtgp_spat_burst), np.std(ses_spat_burst), np.std(holt_spat_burst), np.std(es_spat_burst), np.std(arima_spat_burst), np.std(sarima_spat_burst), np.std(li_spat_burst)])\n",
    "std_rand_entr = np.array([np.std(mtgp_rand_entr), np.std(ses_rand_entr), np.std(holt_rand_entr), np.std(es_rand_entr), np.std(arima_rand_entr), np.std(sarima_rand_entr), np.std(li_rand_entr)])\n",
    "std_real_entr = np.array([np.std(mtgp_real_entr), np.std(ses_real_entr), np.std(holt_real_entr), np.std(es_real_entr), np.std(arima_real_entr), np.std(sarima_real_entr), np.std(li_real_entr)])\n",
    "std_uncorr_entr = np.array([np.std(mtgp_uncorr_entr), np.std(ses_uncorr_entr), np.std(holt_uncorr_entr), np.std(es_uncorr_entr), np.std(arima_uncorr_entr), np.std(sarima_uncorr_entr), np.std(li_uncorr_entr)])\n",
    "\n",
    "# Put averages into a dataframe\n",
    "df_1440_skmob = pd.DataFrame({'Method': ['MTGP', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX', 'LI'],\n",
    "                     'Recency ranking accuracy': avg_rec,\n",
    "                        'Frequency ranking accuracy': avg_freq,\n",
    "                        'Number of locations error': avg_no_loc,\n",
    "                        'Radius of gyration error': avg_k_rg,\n",
    "                        'Real entropy error': avg_real_entr,\n",
    "                        'Random entropy error': avg_rand_entr,\n",
    "                        'Uncorrelated entropy error': avg_uncorr_entr})\n",
    "\n",
    "df_1440_skmob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycle through each file and save results as a numpy array\n",
    "folderpath=\"C:\\\\Users\\\\ekino\\\\OneDrive - UW\\\\GPR\\\\Results\\\\360\\\\all_skmob_metrics\"\n",
    "os.chdir(folderpath)\n",
    "all_file_num=len(glob.glob(\"*.csv\"))\n",
    "print(\"There are\", all_file_num, \"files in the folder\")\n",
    "\n",
    "mtgp_rec = np.array([])\n",
    "mtgp_freq = np.array([])\n",
    "mtgp_no_loc = np.array([])\n",
    "mtgp_k_rg = np.array([])\n",
    "mtgp_spat_burst = np.array([])\n",
    "mtgp_rand_entr = np.array([])\n",
    "mtgp_real_entr = np.array([])\n",
    "mtgp_uncorr_entr = np.array([])\n",
    "mtgp_mae = np.array([])\n",
    "ses_rec = np.array([])\n",
    "ses_freq = np.array([])\n",
    "ses_no_loc = np.array([])\n",
    "ses_k_rg = np.array([])\n",
    "ses_spat_burst = np.array([])\n",
    "ses_rand_entr = np.array([])\n",
    "ses_real_entr = np.array([])\n",
    "ses_uncorr_entr = np.array([])\n",
    "ses_mae = np.array([])\n",
    "holt_rec = np.array([])\n",
    "holt_freq = np.array([])\n",
    "holt_no_loc = np.array([])\n",
    "holt_k_rg = np.array([])\n",
    "holt_spat_burst = np.array([])\n",
    "holt_rand_entr = np.array([])\n",
    "holt_real_entr = np.array([])\n",
    "holt_uncorr_entr = np.array([])\n",
    "holt_mae = np.array([])\n",
    "es_rec = np.array([])\n",
    "es_freq = np.array([])\n",
    "es_no_loc = np.array([])\n",
    "es_k_rg = np.array([])\n",
    "es_spat_burst = np.array([])\n",
    "es_rand_entr = np.array([])\n",
    "es_real_entr = np.array([])\n",
    "es_uncorr_entr = np.array([])\n",
    "es_mae = np.array([])\n",
    "arima_rec = np.array([])\n",
    "arima_freq = np.array([])\n",
    "arima_no_loc = np.array([])\n",
    "arima_k_rg = np.array([])\n",
    "arima_spat_burst = np.array([])\n",
    "arima_rand_entr = np.array([])\n",
    "arima_real_entr = np.array([])\n",
    "arima_uncorr_entr = np.array([])\n",
    "arima_mae = np.array([])\n",
    "sarima_rec = np.array([])\n",
    "sarima_freq = np.array([])\n",
    "sarima_no_loc = np.array([])\n",
    "sarima_k_rg = np.array([])\n",
    "sarima_spat_burst = np.array([])\n",
    "sarima_rand_entr = np.array([])\n",
    "sarima_real_entr = np.array([])\n",
    "sarima_uncorr_entr = np.array([])\n",
    "sarima_mae = np.array([])\n",
    "li_rec = np.array([])\n",
    "li_freq = np.array([])\n",
    "li_no_loc = np.array([])\n",
    "li_k_rg = np.array([])\n",
    "li_spat_burst = np.array([])\n",
    "li_rand_entr = np.array([])\n",
    "li_real_entr = np.array([])\n",
    "li_uncorr_entr = np.array([])\n",
    "li_mae = np.array([])\n",
    "\n",
    "\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    res = pd.read_csv(file, header=0)\n",
    "    # Store each metric in a numpy array\n",
    "    mtgp_rec = np.append(mtgp_rec, res['recency'][0])\n",
    "    mtgp_freq = np.append(mtgp_freq, res['freq_rank'][0])\n",
    "    mtgp_no_loc = np.append(mtgp_no_loc, res['no_loc_error'][0])\n",
    "    mtgp_k_rg = np.append(mtgp_k_rg, res['k_rg_error'][0])\n",
    "    mtgp_spat_burst = np.append(mtgp_spat_burst, res['spat_burst_error'][0])\n",
    "    mtgp_rand_entr = np.append(mtgp_rand_entr, res['rand_entr_error'][0])\n",
    "    mtgp_real_entr = np.append(mtgp_real_entr, res['real_entr_error'][0])\n",
    "    mtgp_uncorr_entr = np.append(mtgp_uncorr_entr, res['uncorr_entr_error'][0])\n",
    "    mtgp_mae = np.append(mtgp_mae, res['mae'][0])\n",
    "    ses_rec = np.append(ses_rec, res['recency'][1])\n",
    "    ses_freq = np.append(ses_freq, res['freq_rank'][1])\n",
    "    ses_no_loc = np.append(ses_no_loc, res['no_loc_error'][1])\n",
    "    ses_k_rg = np.append(ses_k_rg, res['k_rg_error'][1])\n",
    "    ses_spat_burst = np.append(ses_spat_burst, res['spat_burst_error'][1])\n",
    "    ses_rand_entr = np.append(ses_rand_entr, res['rand_entr_error'][1])\n",
    "    ses_real_entr = np.append(ses_real_entr, res['real_entr_error'][1])\n",
    "    ses_uncorr_entr = np.append(ses_uncorr_entr, res['uncorr_entr_error'][1])\n",
    "    ses_mae = np.append(ses_mae, res['mae'][1])\n",
    "    holt_rec = np.append(holt_rec, res['recency'][2])\n",
    "    holt_freq = np.append(holt_freq, res['freq_rank'][2])\n",
    "    holt_no_loc = np.append(holt_no_loc, res['no_loc_error'][2])\n",
    "    holt_k_rg = np.append(holt_k_rg, res['k_rg_error'][2])\n",
    "    holt_spat_burst = np.append(holt_spat_burst, res['spat_burst_error'][2])\n",
    "    holt_rand_entr = np.append(holt_rand_entr, res['rand_entr_error'][2])\n",
    "    holt_real_entr = np.append(holt_real_entr, res['real_entr_error'][2])\n",
    "    holt_uncorr_entr = np.append(holt_uncorr_entr, res['uncorr_entr_error'][2])\n",
    "    holt_mae = np.append(holt_mae, res['mae'][2])\n",
    "    es_rec = np.append(es_rec, res['recency'][3])\n",
    "    es_freq = np.append(es_freq, res['freq_rank'][3])\n",
    "    es_no_loc = np.append(es_no_loc, res['no_loc_error'][3])\n",
    "    es_k_rg = np.append(es_k_rg, res['k_rg_error'][3])\n",
    "    es_spat_burst = np.append(es_spat_burst, res['spat_burst_error'][3])\n",
    "    es_rand_entr = np.append(es_rand_entr, res['rand_entr_error'][3])\n",
    "    es_real_entr = np.append(es_real_entr, res['real_entr_error'][3])\n",
    "    es_uncorr_entr = np.append(es_uncorr_entr, res['uncorr_entr_error'][3])\n",
    "    es_mae = np.append(es_mae, res['mae'][3])\n",
    "    arima_rec = np.append(arima_rec, res['recency'][4])\n",
    "    arima_freq = np.append(arima_freq, res['freq_rank'][4])\n",
    "    arima_no_loc = np.append(arima_no_loc, res['no_loc_error'][4])\n",
    "    arima_k_rg = np.append(arima_k_rg, res['k_rg_error'][4])\n",
    "    arima_spat_burst = np.append(arima_spat_burst, res['spat_burst_error'][4])\n",
    "    arima_rand_entr = np.append(arima_rand_entr, res['rand_entr_error'][4])\n",
    "    arima_real_entr = np.append(arima_real_entr, res['real_entr_error'][4])\n",
    "    arima_uncorr_entr = np.append(arima_uncorr_entr, res['uncorr_entr_error'][4])\n",
    "    arima_mae = np.append(arima_mae, res['mae'][4])\n",
    "    sarima_rec = np.append(sarima_rec, res['recency'][5])\n",
    "    sarima_freq = np.append(sarima_freq, res['freq_rank'][5])\n",
    "    sarima_no_loc = np.append(sarima_no_loc, res['no_loc_error'][5])\n",
    "    sarima_k_rg = np.append(sarima_k_rg, res['k_rg_error'][5])\n",
    "    sarima_spat_burst = np.append(sarima_spat_burst, res['spat_burst_error'][5])\n",
    "    sarima_rand_entr = np.append(sarima_rand_entr, res['rand_entr_error'][5])\n",
    "    sarima_real_entr = np.append(sarima_real_entr, res['real_entr_error'][5])\n",
    "    sarima_uncorr_entr = np.append(sarima_uncorr_entr, res['uncorr_entr_error'][5])\n",
    "    sarima_mae = np.append(sarima_mae, res['mae'][5])\n",
    "    li_rec = np.append(li_rec, res['recency'][6])\n",
    "    li_freq = np.append(li_freq, res['freq_rank'][6])\n",
    "    li_no_loc = np.append(li_no_loc, res['no_loc_error'][6])\n",
    "    li_k_rg = np.append(li_k_rg, res['k_rg_error'][6])\n",
    "    li_spat_burst = np.append(li_spat_burst, res['spat_burst_error'][6])\n",
    "    li_rand_entr = np.append(li_rand_entr, res['rand_entr_error'][6])\n",
    "    li_real_entr = np.append(li_real_entr, res['real_entr_error'][6])\n",
    "    li_uncorr_entr = np.append(li_uncorr_entr, res['uncorr_entr_error'][6])\n",
    "    li_mae = np.append(li_mae, res['mae'][6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the average value of the metrics for each method\n",
    "avg_rec = np.array([np.mean(mtgp_rec), np.mean(ses_rec), np.mean(holt_rec), np.mean(es_rec), np.mean(arima_rec), np.mean(sarima_rec), np.mean(li_rec)])\n",
    "avg_freq = np.array([np.mean(mtgp_freq), np.mean(ses_freq), np.mean(holt_freq), np.mean(es_freq), np.mean(arima_freq), np.mean(sarima_freq), np.mean(li_freq)])\n",
    "avg_no_loc = np.array([np.mean(mtgp_no_loc), np.mean(ses_no_loc), np.mean(holt_no_loc), np.mean(es_no_loc), np.mean(arima_no_loc), np.mean(sarima_no_loc), np.mean(li_no_loc)])\n",
    "avg_k_rg = np.array([np.mean(mtgp_k_rg), np.mean(ses_k_rg), np.mean(holt_k_rg), np.mean(es_k_rg), np.mean(arima_k_rg), np.mean(sarima_k_rg), np.mean(li_k_rg)])\n",
    "avg_spat_burst = np.array([np.mean(mtgp_spat_burst), np.mean(ses_spat_burst), np.mean(holt_spat_burst), np.mean(es_spat_burst), np.mean(arima_spat_burst), np.mean(sarima_spat_burst), np.mean(li_spat_burst)])\n",
    "avg_rand_entr = np.array([np.mean(mtgp_rand_entr), np.mean(ses_rand_entr), np.mean(holt_rand_entr), np.mean(es_rand_entr), np.mean(arima_rand_entr), np.mean(sarima_rand_entr), np.mean(li_rand_entr)])\n",
    "avg_real_entr = np.array([np.mean(mtgp_real_entr), np.mean(ses_real_entr), np.mean(holt_real_entr), np.mean(es_real_entr), np.mean(arima_real_entr), np.mean(sarima_real_entr), np.mean(li_real_entr)])\n",
    "avg_uncorr_entr = np.array([np.mean(mtgp_uncorr_entr), np.mean(ses_uncorr_entr), np.mean(holt_uncorr_entr), np.mean(es_uncorr_entr), np.mean(arima_uncorr_entr), np.mean(sarima_uncorr_entr), np.mean(li_uncorr_entr)])\n",
    "\n",
    "# Get the standard deviation of the metrics for each method\n",
    "std_rec = np.array([np.std(mtgp_rec), np.std(ses_rec), np.std(holt_rec), np.std(es_rec), np.std(arima_rec), np.std(sarima_rec), np.std(li_rec)])\n",
    "std_freq = np.array([np.std(mtgp_freq), np.std(ses_freq), np.std(holt_freq), np.std(es_freq), np.std(arima_freq), np.std(sarima_freq), np.std(li_freq)])\n",
    "std_no_loc = np.array([np.std(mtgp_no_loc), np.std(ses_no_loc), np.std(holt_no_loc), np.std(es_no_loc), np.std(arima_no_loc), np.std(sarima_no_loc), np.std(li_no_loc)])\n",
    "std_k_rg = np.array([np.std(mtgp_k_rg), np.std(ses_k_rg), np.std(holt_k_rg), np.std(es_k_rg), np.std(arima_k_rg), np.std(sarima_k_rg), np.std(li_k_rg)])\n",
    "std_spat_burst = np.array([np.std(mtgp_spat_burst), np.std(ses_spat_burst), np.std(holt_spat_burst), np.std(es_spat_burst), np.std(arima_spat_burst), np.std(sarima_spat_burst), np.std(li_spat_burst)])\n",
    "std_rand_entr = np.array([np.std(mtgp_rand_entr), np.std(ses_rand_entr), np.std(holt_rand_entr), np.std(es_rand_entr), np.std(arima_rand_entr), np.std(sarima_rand_entr), np.std(li_rand_entr)])\n",
    "std_real_entr = np.array([np.std(mtgp_real_entr), np.std(ses_real_entr), np.std(holt_real_entr), np.std(es_real_entr), np.std(arima_real_entr), np.std(sarima_real_entr), np.std(li_real_entr)])\n",
    "std_uncorr_entr = np.array([np.std(mtgp_uncorr_entr), np.std(ses_uncorr_entr), np.std(holt_uncorr_entr), np.std(es_uncorr_entr), np.std(arima_uncorr_entr), np.std(sarima_uncorr_entr), np.std(li_uncorr_entr)])\n",
    "\n",
    "# Put averages into a dataframe\n",
    "df_360_skmob = pd.DataFrame({'Method': ['MTGP', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX', 'LI'],\n",
    "                     'Recency ranking accuracy': avg_rec,\n",
    "                        'Frequency ranking accuracy': avg_freq,\n",
    "                        'Number of locations error': avg_no_loc,\n",
    "                        'Radius of gyration error': avg_k_rg,\n",
    "                        'Real entropy error': avg_real_entr,\n",
    "                        'Random entropy error': avg_rand_entr,\n",
    "                        'Uncorrelated entropy error': avg_uncorr_entr})\n",
    "\n",
    "df_360_skmob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycle through each file and save results as a numpy array\n",
    "folderpath=\"C:\\\\Users\\\\ekino\\\\OneDrive - UW\\\\GPR\\\\Results\\\\60\\\\all_skmob_metrics\"\n",
    "os.chdir(folderpath)\n",
    "all_file_num=len(glob.glob(\"*.csv\"))\n",
    "print(\"There are\", all_file_num, \"files in the folder\")\n",
    "\n",
    "mtgp_rec = np.array([])\n",
    "mtgp_freq = np.array([])\n",
    "mtgp_no_loc = np.array([])\n",
    "mtgp_k_rg = np.array([])\n",
    "mtgp_spat_burst = np.array([])\n",
    "mtgp_rand_entr = np.array([])\n",
    "mtgp_real_entr = np.array([])\n",
    "mtgp_uncorr_entr = np.array([])\n",
    "mtgp_mae = np.array([])\n",
    "ses_rec = np.array([])\n",
    "ses_freq = np.array([])\n",
    "ses_no_loc = np.array([])\n",
    "ses_k_rg = np.array([])\n",
    "ses_spat_burst = np.array([])\n",
    "ses_rand_entr = np.array([])\n",
    "ses_real_entr = np.array([])\n",
    "ses_uncorr_entr = np.array([])\n",
    "ses_mae = np.array([])\n",
    "holt_rec = np.array([])\n",
    "holt_freq = np.array([])\n",
    "holt_no_loc = np.array([])\n",
    "holt_k_rg = np.array([])\n",
    "holt_spat_burst = np.array([])\n",
    "holt_rand_entr = np.array([])\n",
    "holt_real_entr = np.array([])\n",
    "holt_uncorr_entr = np.array([])\n",
    "holt_mae = np.array([])\n",
    "es_rec = np.array([])\n",
    "es_freq = np.array([])\n",
    "es_no_loc = np.array([])\n",
    "es_k_rg = np.array([])\n",
    "es_spat_burst = np.array([])\n",
    "es_rand_entr = np.array([])\n",
    "es_real_entr = np.array([])\n",
    "es_uncorr_entr = np.array([])\n",
    "es_mae = np.array([])\n",
    "arima_rec = np.array([])\n",
    "arima_freq = np.array([])\n",
    "arima_no_loc = np.array([])\n",
    "arima_k_rg = np.array([])\n",
    "arima_spat_burst = np.array([])\n",
    "arima_rand_entr = np.array([])\n",
    "arima_real_entr = np.array([])\n",
    "arima_uncorr_entr = np.array([])\n",
    "arima_mae = np.array([])\n",
    "sarima_rec = np.array([])\n",
    "sarima_freq = np.array([])\n",
    "sarima_no_loc = np.array([])\n",
    "sarima_k_rg = np.array([])\n",
    "sarima_spat_burst = np.array([])\n",
    "sarima_rand_entr = np.array([])\n",
    "sarima_real_entr = np.array([])\n",
    "sarima_uncorr_entr = np.array([])\n",
    "sarima_mae = np.array([])\n",
    "li_rec = np.array([])\n",
    "li_freq = np.array([])\n",
    "li_no_loc = np.array([])\n",
    "li_k_rg = np.array([])\n",
    "li_spat_burst = np.array([])\n",
    "li_rand_entr = np.array([])\n",
    "li_real_entr = np.array([])\n",
    "li_uncorr_entr = np.array([])\n",
    "li_mae = np.array([])\n",
    "\n",
    "\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    res = pd.read_csv(file, header=0)\n",
    "    # Store each metric in a numpy array\n",
    "    mtgp_rec = np.append(mtgp_rec, res['recency'][0])\n",
    "    mtgp_freq = np.append(mtgp_freq, res['freq_rank'][0])\n",
    "    mtgp_no_loc = np.append(mtgp_no_loc, res['no_loc_error'][0])\n",
    "    mtgp_k_rg = np.append(mtgp_k_rg, res['k_rg_error'][0])\n",
    "    mtgp_spat_burst = np.append(mtgp_spat_burst, res['spat_burst_error'][0])\n",
    "    mtgp_rand_entr = np.append(mtgp_rand_entr, res['rand_entr_error'][0])\n",
    "    mtgp_real_entr = np.append(mtgp_real_entr, res['real_entr_error'][0])\n",
    "    mtgp_uncorr_entr = np.append(mtgp_uncorr_entr, res['uncorr_entr_error'][0])\n",
    "    mtgp_mae = np.append(mtgp_mae, res['mae'][0])\n",
    "    ses_rec = np.append(ses_rec, res['recency'][1])\n",
    "    ses_freq = np.append(ses_freq, res['freq_rank'][1])\n",
    "    ses_no_loc = np.append(ses_no_loc, res['no_loc_error'][1])\n",
    "    ses_k_rg = np.append(ses_k_rg, res['k_rg_error'][1])\n",
    "    ses_spat_burst = np.append(ses_spat_burst, res['spat_burst_error'][1])\n",
    "    ses_rand_entr = np.append(ses_rand_entr, res['rand_entr_error'][1])\n",
    "    ses_real_entr = np.append(ses_real_entr, res['real_entr_error'][1])\n",
    "    ses_uncorr_entr = np.append(ses_uncorr_entr, res['uncorr_entr_error'][1])\n",
    "    ses_mae = np.append(ses_mae, res['mae'][1])\n",
    "    holt_rec = np.append(holt_rec, res['recency'][2])\n",
    "    holt_freq = np.append(holt_freq, res['freq_rank'][2])\n",
    "    holt_no_loc = np.append(holt_no_loc, res['no_loc_error'][2])\n",
    "    holt_k_rg = np.append(holt_k_rg, res['k_rg_error'][2])\n",
    "    holt_spat_burst = np.append(holt_spat_burst, res['spat_burst_error'][2])\n",
    "    holt_rand_entr = np.append(holt_rand_entr, res['rand_entr_error'][2])\n",
    "    holt_real_entr = np.append(holt_real_entr, res['real_entr_error'][2])\n",
    "    holt_uncorr_entr = np.append(holt_uncorr_entr, res['uncorr_entr_error'][2])\n",
    "    holt_mae = np.append(holt_mae, res['mae'][2])\n",
    "    es_rec = np.append(es_rec, res['recency'][3])\n",
    "    es_freq = np.append(es_freq, res['freq_rank'][3])\n",
    "    es_no_loc = np.append(es_no_loc, res['no_loc_error'][3])\n",
    "    es_k_rg = np.append(es_k_rg, res['k_rg_error'][3])\n",
    "    es_spat_burst = np.append(es_spat_burst, res['spat_burst_error'][3])\n",
    "    es_rand_entr = np.append(es_rand_entr, res['rand_entr_error'][3])\n",
    "    es_real_entr = np.append(es_real_entr, res['real_entr_error'][3])\n",
    "    es_uncorr_entr = np.append(es_uncorr_entr, res['uncorr_entr_error'][3])\n",
    "    es_mae = np.append(es_mae, res['mae'][3])\n",
    "    arima_rec = np.append(arima_rec, res['recency'][4])\n",
    "    arima_freq = np.append(arima_freq, res['freq_rank'][4])\n",
    "    arima_no_loc = np.append(arima_no_loc, res['no_loc_error'][4])\n",
    "    arima_k_rg = np.append(arima_k_rg, res['k_rg_error'][4])\n",
    "    arima_spat_burst = np.append(arima_spat_burst, res['spat_burst_error'][4])\n",
    "    arima_rand_entr = np.append(arima_rand_entr, res['rand_entr_error'][4])\n",
    "    arima_real_entr = np.append(arima_real_entr, res['real_entr_error'][4])\n",
    "    arima_uncorr_entr = np.append(arima_uncorr_entr, res['uncorr_entr_error'][4])\n",
    "    arima_mae = np.append(arima_mae, res['mae'][4])\n",
    "    sarima_rec = np.append(sarima_rec, res['recency'][5])\n",
    "    sarima_freq = np.append(sarima_freq, res['freq_rank'][5])\n",
    "    sarima_no_loc = np.append(sarima_no_loc, res['no_loc_error'][5])\n",
    "    sarima_k_rg = np.append(sarima_k_rg, res['k_rg_error'][5])\n",
    "    sarima_spat_burst = np.append(sarima_spat_burst, res['spat_burst_error'][5])\n",
    "    sarima_rand_entr = np.append(sarima_rand_entr, res['rand_entr_error'][5])\n",
    "    sarima_real_entr = np.append(sarima_real_entr, res['real_entr_error'][5])\n",
    "    sarima_uncorr_entr = np.append(sarima_uncorr_entr, res['uncorr_entr_error'][5])\n",
    "    sarima_mae = np.append(sarima_mae, res['mae'][5])\n",
    "    li_rec = np.append(li_rec, res['recency'][6])\n",
    "    li_freq = np.append(li_freq, res['freq_rank'][6])\n",
    "    li_no_loc = np.append(li_no_loc, res['no_loc_error'][6])\n",
    "    li_k_rg = np.append(li_k_rg, res['k_rg_error'][6])\n",
    "    li_spat_burst = np.append(li_spat_burst, res['spat_burst_error'][6])\n",
    "    li_rand_entr = np.append(li_rand_entr, res['rand_entr_error'][6])\n",
    "    li_real_entr = np.append(li_real_entr, res['real_entr_error'][6])\n",
    "    li_uncorr_entr = np.append(li_uncorr_entr, res['uncorr_entr_error'][6])\n",
    "    li_mae = np.append(li_mae, res['mae'][6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the average value of the metrics for each method\n",
    "avg_rec = np.array([np.mean(mtgp_rec), np.mean(ses_rec), np.mean(holt_rec), np.mean(es_rec), np.mean(arima_rec), np.mean(sarima_rec), np.mean(li_rec)])\n",
    "avg_freq = np.array([np.mean(mtgp_freq), np.mean(ses_freq), np.mean(holt_freq), np.mean(es_freq), np.mean(arima_freq), np.mean(sarima_freq), np.mean(li_freq)])\n",
    "avg_no_loc = np.array([np.mean(mtgp_no_loc), np.mean(ses_no_loc), np.mean(holt_no_loc), np.mean(es_no_loc), np.mean(arima_no_loc), np.mean(sarima_no_loc), np.mean(li_no_loc)])\n",
    "avg_k_rg = np.array([np.mean(mtgp_k_rg), np.mean(ses_k_rg), np.mean(holt_k_rg), np.mean(es_k_rg), np.mean(arima_k_rg), np.mean(sarima_k_rg), np.mean(li_k_rg)])\n",
    "avg_spat_burst = np.array([np.mean(mtgp_spat_burst), np.mean(ses_spat_burst), np.mean(holt_spat_burst), np.mean(es_spat_burst), np.mean(arima_spat_burst), np.mean(sarima_spat_burst), np.mean(li_spat_burst)])\n",
    "avg_rand_entr = np.array([np.mean(mtgp_rand_entr), np.mean(ses_rand_entr), np.mean(holt_rand_entr), np.mean(es_rand_entr), np.mean(arima_rand_entr), np.mean(sarima_rand_entr), np.mean(li_rand_entr)])\n",
    "avg_real_entr = np.array([np.mean(mtgp_real_entr), np.mean(ses_real_entr), np.mean(holt_real_entr), np.mean(es_real_entr), np.mean(arima_real_entr), np.mean(sarima_real_entr), np.mean(li_real_entr)])\n",
    "avg_uncorr_entr = np.array([np.mean(mtgp_uncorr_entr), np.mean(ses_uncorr_entr), np.mean(holt_uncorr_entr), np.mean(es_uncorr_entr), np.mean(arima_uncorr_entr), np.mean(sarima_uncorr_entr), np.mean(li_uncorr_entr)])\n",
    "\n",
    "# Get the standard deviation of the metrics for each method\n",
    "std_rec = np.array([np.std(mtgp_rec), np.std(ses_rec), np.std(holt_rec), np.std(es_rec), np.std(arima_rec), np.std(sarima_rec), np.std(li_rec)])\n",
    "std_freq = np.array([np.std(mtgp_freq), np.std(ses_freq), np.std(holt_freq), np.std(es_freq), np.std(arima_freq), np.std(sarima_freq), np.std(li_freq)])\n",
    "std_no_loc = np.array([np.std(mtgp_no_loc), np.std(ses_no_loc), np.std(holt_no_loc), np.std(es_no_loc), np.std(arima_no_loc), np.std(sarima_no_loc), np.std(li_no_loc)])\n",
    "std_k_rg = np.array([np.std(mtgp_k_rg), np.std(ses_k_rg), np.std(holt_k_rg), np.std(es_k_rg), np.std(arima_k_rg), np.std(sarima_k_rg), np.std(li_k_rg)])\n",
    "std_spat_burst = np.array([np.std(mtgp_spat_burst), np.std(ses_spat_burst), np.std(holt_spat_burst), np.std(es_spat_burst), np.std(arima_spat_burst), np.std(sarima_spat_burst), np.std(li_spat_burst)])\n",
    "std_rand_entr = np.array([np.std(mtgp_rand_entr), np.std(ses_rand_entr), np.std(holt_rand_entr), np.std(es_rand_entr), np.std(arima_rand_entr), np.std(sarima_rand_entr), np.std(li_rand_entr)])\n",
    "std_real_entr = np.array([np.std(mtgp_real_entr), np.std(ses_real_entr), np.std(holt_real_entr), np.std(es_real_entr), np.std(arima_real_entr), np.std(sarima_real_entr), np.std(li_real_entr)])\n",
    "std_uncorr_entr = np.array([np.std(mtgp_uncorr_entr), np.std(ses_uncorr_entr), np.std(holt_uncorr_entr), np.std(es_uncorr_entr), np.std(arima_uncorr_entr), np.std(sarima_uncorr_entr), np.std(li_uncorr_entr)])\n",
    "\n",
    "# Put averages into a dataframe\n",
    "df_60_skmob = pd.DataFrame({'Method': ['MTGP', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX', 'LI'],\n",
    "                     'Recency ranking accuracy': avg_rec,\n",
    "                        'Frequency ranking accuracy': avg_freq,\n",
    "                        'Number of locations error': avg_no_loc,\n",
    "                        'Radius of gyration error': avg_k_rg,\n",
    "                        'Real entropy error': avg_real_entr,\n",
    "                        'Random entropy error': avg_rand_entr,\n",
    "                        'Uncorrelated entropy error': avg_uncorr_entr})\n",
    "\n",
    "df_60_skmob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycle through each file and save results as a numpy array\n",
    "folderpath=\"C:\\\\Users\\\\ekino\\\\OneDrive - UW\\\\GPR\\\\Results\\\\30\\\\all_skmob_metrics\"\n",
    "os.chdir(folderpath)\n",
    "all_file_num=len(glob.glob(\"*.csv\"))\n",
    "print(\"There are\", all_file_num, \"files in the folder\")\n",
    "\n",
    "mtgp_rec = np.array([])\n",
    "mtgp_freq = np.array([])\n",
    "mtgp_no_loc = np.array([])\n",
    "mtgp_k_rg = np.array([])\n",
    "mtgp_spat_burst = np.array([])\n",
    "mtgp_rand_entr = np.array([])\n",
    "mtgp_real_entr = np.array([])\n",
    "mtgp_uncorr_entr = np.array([])\n",
    "mtgp_mae = np.array([])\n",
    "ses_rec = np.array([])\n",
    "ses_freq = np.array([])\n",
    "ses_no_loc = np.array([])\n",
    "ses_k_rg = np.array([])\n",
    "ses_spat_burst = np.array([])\n",
    "ses_rand_entr = np.array([])\n",
    "ses_real_entr = np.array([])\n",
    "ses_uncorr_entr = np.array([])\n",
    "ses_mae = np.array([])\n",
    "holt_rec = np.array([])\n",
    "holt_freq = np.array([])\n",
    "holt_no_loc = np.array([])\n",
    "holt_k_rg = np.array([])\n",
    "holt_spat_burst = np.array([])\n",
    "holt_rand_entr = np.array([])\n",
    "holt_real_entr = np.array([])\n",
    "holt_uncorr_entr = np.array([])\n",
    "holt_mae = np.array([])\n",
    "es_rec = np.array([])\n",
    "es_freq = np.array([])\n",
    "es_no_loc = np.array([])\n",
    "es_k_rg = np.array([])\n",
    "es_spat_burst = np.array([])\n",
    "es_rand_entr = np.array([])\n",
    "es_real_entr = np.array([])\n",
    "es_uncorr_entr = np.array([])\n",
    "es_mae = np.array([])\n",
    "arima_rec = np.array([])\n",
    "arima_freq = np.array([])\n",
    "arima_no_loc = np.array([])\n",
    "arima_k_rg = np.array([])\n",
    "arima_spat_burst = np.array([])\n",
    "arima_rand_entr = np.array([])\n",
    "arima_real_entr = np.array([])\n",
    "arima_uncorr_entr = np.array([])\n",
    "arima_mae = np.array([])\n",
    "sarima_rec = np.array([])\n",
    "sarima_freq = np.array([])\n",
    "sarima_no_loc = np.array([])\n",
    "sarima_k_rg = np.array([])\n",
    "sarima_spat_burst = np.array([])\n",
    "sarima_rand_entr = np.array([])\n",
    "sarima_real_entr = np.array([])\n",
    "sarima_uncorr_entr = np.array([])\n",
    "sarima_mae = np.array([])\n",
    "li_rec = np.array([])\n",
    "li_freq = np.array([])\n",
    "li_no_loc = np.array([])\n",
    "li_k_rg = np.array([])\n",
    "li_spat_burst = np.array([])\n",
    "li_rand_entr = np.array([])\n",
    "li_real_entr = np.array([])\n",
    "li_uncorr_entr = np.array([])\n",
    "li_mae = np.array([])\n",
    "\n",
    "\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    res = pd.read_csv(file, header=0)\n",
    "    # Store each metric in a numpy array\n",
    "    mtgp_rec = np.append(mtgp_rec, res['recency'][0])\n",
    "    mtgp_freq = np.append(mtgp_freq, res['freq_rank'][0])\n",
    "    mtgp_no_loc = np.append(mtgp_no_loc, res['no_loc_error'][0])\n",
    "    mtgp_k_rg = np.append(mtgp_k_rg, res['k_rg_error'][0])\n",
    "    mtgp_spat_burst = np.append(mtgp_spat_burst, res['spat_burst_error'][0])\n",
    "    mtgp_rand_entr = np.append(mtgp_rand_entr, res['rand_entr_error'][0])\n",
    "    mtgp_real_entr = np.append(mtgp_real_entr, res['real_entr_error'][0])\n",
    "    mtgp_uncorr_entr = np.append(mtgp_uncorr_entr, res['uncorr_entr_error'][0])\n",
    "    mtgp_mae = np.append(mtgp_mae, res['mae'][0])\n",
    "    ses_rec = np.append(ses_rec, res['recency'][1])\n",
    "    ses_freq = np.append(ses_freq, res['freq_rank'][1])\n",
    "    ses_no_loc = np.append(ses_no_loc, res['no_loc_error'][1])\n",
    "    ses_k_rg = np.append(ses_k_rg, res['k_rg_error'][1])\n",
    "    ses_spat_burst = np.append(ses_spat_burst, res['spat_burst_error'][1])\n",
    "    ses_rand_entr = np.append(ses_rand_entr, res['rand_entr_error'][1])\n",
    "    ses_real_entr = np.append(ses_real_entr, res['real_entr_error'][1])\n",
    "    ses_uncorr_entr = np.append(ses_uncorr_entr, res['uncorr_entr_error'][1])\n",
    "    ses_mae = np.append(ses_mae, res['mae'][1])\n",
    "    holt_rec = np.append(holt_rec, res['recency'][2])\n",
    "    holt_freq = np.append(holt_freq, res['freq_rank'][2])\n",
    "    holt_no_loc = np.append(holt_no_loc, res['no_loc_error'][2])\n",
    "    holt_k_rg = np.append(holt_k_rg, res['k_rg_error'][2])\n",
    "    holt_spat_burst = np.append(holt_spat_burst, res['spat_burst_error'][2])\n",
    "    holt_rand_entr = np.append(holt_rand_entr, res['rand_entr_error'][2])\n",
    "    holt_real_entr = np.append(holt_real_entr, res['real_entr_error'][2])\n",
    "    holt_uncorr_entr = np.append(holt_uncorr_entr, res['uncorr_entr_error'][2])\n",
    "    holt_mae = np.append(holt_mae, res['mae'][2])\n",
    "    es_rec = np.append(es_rec, res['recency'][3])\n",
    "    es_freq = np.append(es_freq, res['freq_rank'][3])\n",
    "    es_no_loc = np.append(es_no_loc, res['no_loc_error'][3])\n",
    "    es_k_rg = np.append(es_k_rg, res['k_rg_error'][3])\n",
    "    es_spat_burst = np.append(es_spat_burst, res['spat_burst_error'][3])\n",
    "    es_rand_entr = np.append(es_rand_entr, res['rand_entr_error'][3])\n",
    "    es_real_entr = np.append(es_real_entr, res['real_entr_error'][3])\n",
    "    es_uncorr_entr = np.append(es_uncorr_entr, res['uncorr_entr_error'][3])\n",
    "    es_mae = np.append(es_mae, res['mae'][3])\n",
    "    arima_rec = np.append(arima_rec, res['recency'][4])\n",
    "    arima_freq = np.append(arima_freq, res['freq_rank'][4])\n",
    "    arima_no_loc = np.append(arima_no_loc, res['no_loc_error'][4])\n",
    "    arima_k_rg = np.append(arima_k_rg, res['k_rg_error'][4])\n",
    "    arima_spat_burst = np.append(arima_spat_burst, res['spat_burst_error'][4])\n",
    "    arima_rand_entr = np.append(arima_rand_entr, res['rand_entr_error'][4])\n",
    "    arima_real_entr = np.append(arima_real_entr, res['real_entr_error'][4])\n",
    "    arima_uncorr_entr = np.append(arima_uncorr_entr, res['uncorr_entr_error'][4])\n",
    "    arima_mae = np.append(arima_mae, res['mae'][4])\n",
    "    sarima_rec = np.append(sarima_rec, res['recency'][5])\n",
    "    sarima_freq = np.append(sarima_freq, res['freq_rank'][5])\n",
    "    sarima_no_loc = np.append(sarima_no_loc, res['no_loc_error'][5])\n",
    "    sarima_k_rg = np.append(sarima_k_rg, res['k_rg_error'][5])\n",
    "    sarima_spat_burst = np.append(sarima_spat_burst, res['spat_burst_error'][5])\n",
    "    sarima_rand_entr = np.append(sarima_rand_entr, res['rand_entr_error'][5])\n",
    "    sarima_real_entr = np.append(sarima_real_entr, res['real_entr_error'][5])\n",
    "    sarima_uncorr_entr = np.append(sarima_uncorr_entr, res['uncorr_entr_error'][5])\n",
    "    sarima_mae = np.append(sarima_mae, res['mae'][5])\n",
    "    li_rec = np.append(li_rec, res['recency'][6])\n",
    "    li_freq = np.append(li_freq, res['freq_rank'][6])\n",
    "    li_no_loc = np.append(li_no_loc, res['no_loc_error'][6])\n",
    "    li_k_rg = np.append(li_k_rg, res['k_rg_error'][6])\n",
    "    li_spat_burst = np.append(li_spat_burst, res['spat_burst_error'][6])\n",
    "    li_rand_entr = np.append(li_rand_entr, res['rand_entr_error'][6])\n",
    "    li_real_entr = np.append(li_real_entr, res['real_entr_error'][6])\n",
    "    li_uncorr_entr = np.append(li_uncorr_entr, res['uncorr_entr_error'][6])\n",
    "    li_mae = np.append(li_mae, res['mae'][6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the average value of the metrics for each method\n",
    "avg_rec = np.array([np.mean(mtgp_rec), np.mean(ses_rec), np.mean(holt_rec), np.mean(es_rec), np.mean(arima_rec), np.mean(sarima_rec), np.mean(li_rec)])\n",
    "avg_freq = np.array([np.mean(mtgp_freq), np.mean(ses_freq), np.mean(holt_freq), np.mean(es_freq), np.mean(arima_freq), np.mean(sarima_freq), np.mean(li_freq)])\n",
    "avg_no_loc = np.array([np.mean(mtgp_no_loc), np.mean(ses_no_loc), np.mean(holt_no_loc), np.mean(es_no_loc), np.mean(arima_no_loc), np.mean(sarima_no_loc), np.mean(li_no_loc)])\n",
    "avg_k_rg = np.array([np.mean(mtgp_k_rg), np.mean(ses_k_rg), np.mean(holt_k_rg), np.mean(es_k_rg), np.mean(arima_k_rg), np.mean(sarima_k_rg), np.mean(li_k_rg)])\n",
    "avg_spat_burst = np.array([np.mean(mtgp_spat_burst), np.mean(ses_spat_burst), np.mean(holt_spat_burst), np.mean(es_spat_burst), np.mean(arima_spat_burst), np.mean(sarima_spat_burst), np.mean(li_spat_burst)])\n",
    "avg_rand_entr = np.array([np.mean(mtgp_rand_entr), np.mean(ses_rand_entr), np.mean(holt_rand_entr), np.mean(es_rand_entr), np.mean(arima_rand_entr), np.mean(sarima_rand_entr), np.mean(li_rand_entr)])\n",
    "avg_real_entr = np.array([np.mean(mtgp_real_entr), np.mean(ses_real_entr), np.mean(holt_real_entr), np.mean(es_real_entr), np.mean(arima_real_entr), np.mean(sarima_real_entr), np.mean(li_real_entr)])\n",
    "avg_uncorr_entr = np.array([np.mean(mtgp_uncorr_entr), np.mean(ses_uncorr_entr), np.mean(holt_uncorr_entr), np.mean(es_uncorr_entr), np.mean(arima_uncorr_entr), np.mean(sarima_uncorr_entr), np.mean(li_uncorr_entr)])\n",
    "\n",
    "# Get the standard deviation of the metrics for each method\n",
    "std_rec = np.array([np.std(mtgp_rec), np.std(ses_rec), np.std(holt_rec), np.std(es_rec), np.std(arima_rec), np.std(sarima_rec), np.std(li_rec)])\n",
    "std_freq = np.array([np.std(mtgp_freq), np.std(ses_freq), np.std(holt_freq), np.std(es_freq), np.std(arima_freq), np.std(sarima_freq), np.std(li_freq)])\n",
    "std_no_loc = np.array([np.std(mtgp_no_loc), np.std(ses_no_loc), np.std(holt_no_loc), np.std(es_no_loc), np.std(arima_no_loc), np.std(sarima_no_loc), np.std(li_no_loc)])\n",
    "std_k_rg = np.array([np.std(mtgp_k_rg), np.std(ses_k_rg), np.std(holt_k_rg), np.std(es_k_rg), np.std(arima_k_rg), np.std(sarima_k_rg), np.std(li_k_rg)])\n",
    "std_spat_burst = np.array([np.std(mtgp_spat_burst), np.std(ses_spat_burst), np.std(holt_spat_burst), np.std(es_spat_burst), np.std(arima_spat_burst), np.std(sarima_spat_burst), np.std(li_spat_burst)])\n",
    "std_rand_entr = np.array([np.std(mtgp_rand_entr), np.std(ses_rand_entr), np.std(holt_rand_entr), np.std(es_rand_entr), np.std(arima_rand_entr), np.std(sarima_rand_entr), np.std(li_rand_entr)])\n",
    "std_real_entr = np.array([np.std(mtgp_real_entr), np.std(ses_real_entr), np.std(holt_real_entr), np.std(es_real_entr), np.std(arima_real_entr), np.std(sarima_real_entr), np.std(li_real_entr)])\n",
    "std_uncorr_entr = np.array([np.std(mtgp_uncorr_entr), np.std(ses_uncorr_entr), np.std(holt_uncorr_entr), np.std(es_uncorr_entr), np.std(arima_uncorr_entr), np.std(sarima_uncorr_entr), np.std(li_uncorr_entr)])\n",
    "\n",
    "# Put averages into a dataframe\n",
    "df_30_skmob = pd.DataFrame({'Method': ['MTGP', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX', 'LI'],\n",
    "                     'Recency ranking accuracy': avg_rec,\n",
    "                        'Frequency ranking accuracy': avg_freq,\n",
    "                        'Number of locations error': avg_no_loc,\n",
    "                        'Radius of gyration error': avg_k_rg,\n",
    "                        'Real entropy error': avg_real_entr,\n",
    "                        'Random entropy error': avg_rand_entr,\n",
    "                        'Uncorrelated entropy error': avg_uncorr_entr})\n",
    "\n",
    "df_30_skmob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycle through each file and save results as a numpy array\n",
    "folderpath=\"C:\\\\Users\\\\ekino\\\\OneDrive - UW\\\\GPR\\\\Results\\\\15\\\\all_skmob_metrics\"\n",
    "os.chdir(folderpath)\n",
    "all_file_num=len(glob.glob(\"*.csv\"))\n",
    "print(\"There are\", all_file_num, \"files in the folder\")\n",
    "\n",
    "mtgp_rec = np.array([])\n",
    "mtgp_freq = np.array([])\n",
    "mtgp_no_loc = np.array([])\n",
    "mtgp_k_rg = np.array([])\n",
    "mtgp_spat_burst = np.array([])\n",
    "mtgp_rand_entr = np.array([])\n",
    "mtgp_real_entr = np.array([])\n",
    "mtgp_uncorr_entr = np.array([])\n",
    "mtgp_mae = np.array([])\n",
    "ses_rec = np.array([])\n",
    "ses_freq = np.array([])\n",
    "ses_no_loc = np.array([])\n",
    "ses_k_rg = np.array([])\n",
    "ses_spat_burst = np.array([])\n",
    "ses_rand_entr = np.array([])\n",
    "ses_real_entr = np.array([])\n",
    "ses_uncorr_entr = np.array([])\n",
    "ses_mae = np.array([])\n",
    "holt_rec = np.array([])\n",
    "holt_freq = np.array([])\n",
    "holt_no_loc = np.array([])\n",
    "holt_k_rg = np.array([])\n",
    "holt_spat_burst = np.array([])\n",
    "holt_rand_entr = np.array([])\n",
    "holt_real_entr = np.array([])\n",
    "holt_uncorr_entr = np.array([])\n",
    "holt_mae = np.array([])\n",
    "es_rec = np.array([])\n",
    "es_freq = np.array([])\n",
    "es_no_loc = np.array([])\n",
    "es_k_rg = np.array([])\n",
    "es_spat_burst = np.array([])\n",
    "es_rand_entr = np.array([])\n",
    "es_real_entr = np.array([])\n",
    "es_uncorr_entr = np.array([])\n",
    "es_mae = np.array([])\n",
    "arima_rec = np.array([])\n",
    "arima_freq = np.array([])\n",
    "arima_no_loc = np.array([])\n",
    "arima_k_rg = np.array([])\n",
    "arima_spat_burst = np.array([])\n",
    "arima_rand_entr = np.array([])\n",
    "arima_real_entr = np.array([])\n",
    "arima_uncorr_entr = np.array([])\n",
    "arima_mae = np.array([])\n",
    "sarima_rec = np.array([])\n",
    "sarima_freq = np.array([])\n",
    "sarima_no_loc = np.array([])\n",
    "sarima_k_rg = np.array([])\n",
    "sarima_spat_burst = np.array([])\n",
    "sarima_rand_entr = np.array([])\n",
    "sarima_real_entr = np.array([])\n",
    "sarima_uncorr_entr = np.array([])\n",
    "sarima_mae = np.array([])\n",
    "li_rec = np.array([])\n",
    "li_freq = np.array([])\n",
    "li_no_loc = np.array([])\n",
    "li_k_rg = np.array([])\n",
    "li_spat_burst = np.array([])\n",
    "li_rand_entr = np.array([])\n",
    "li_real_entr = np.array([])\n",
    "li_uncorr_entr = np.array([])\n",
    "li_mae = np.array([])\n",
    "\n",
    "\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    res = pd.read_csv(file, header=0)\n",
    "    # Store each metric in a numpy array\n",
    "    mtgp_rec = np.append(mtgp_rec, res['recency'][0])\n",
    "    mtgp_freq = np.append(mtgp_freq, res['freq_rank'][0])\n",
    "    mtgp_no_loc = np.append(mtgp_no_loc, res['no_loc_error'][0])\n",
    "    mtgp_k_rg = np.append(mtgp_k_rg, res['k_rg_error'][0])\n",
    "    mtgp_spat_burst = np.append(mtgp_spat_burst, res['spat_burst_error'][0])\n",
    "    mtgp_rand_entr = np.append(mtgp_rand_entr, res['rand_entr_error'][0])\n",
    "    mtgp_real_entr = np.append(mtgp_real_entr, res['real_entr_error'][0])\n",
    "    mtgp_uncorr_entr = np.append(mtgp_uncorr_entr, res['uncorr_entr_error'][0])\n",
    "    mtgp_mae = np.append(mtgp_mae, res['mae'][0])\n",
    "    ses_rec = np.append(ses_rec, res['recency'][1])\n",
    "    ses_freq = np.append(ses_freq, res['freq_rank'][1])\n",
    "    ses_no_loc = np.append(ses_no_loc, res['no_loc_error'][1])\n",
    "    ses_k_rg = np.append(ses_k_rg, res['k_rg_error'][1])\n",
    "    ses_spat_burst = np.append(ses_spat_burst, res['spat_burst_error'][1])\n",
    "    ses_rand_entr = np.append(ses_rand_entr, res['rand_entr_error'][1])\n",
    "    ses_real_entr = np.append(ses_real_entr, res['real_entr_error'][1])\n",
    "    ses_uncorr_entr = np.append(ses_uncorr_entr, res['uncorr_entr_error'][1])\n",
    "    ses_mae = np.append(ses_mae, res['mae'][1])\n",
    "    holt_rec = np.append(holt_rec, res['recency'][2])\n",
    "    holt_freq = np.append(holt_freq, res['freq_rank'][2])\n",
    "    holt_no_loc = np.append(holt_no_loc, res['no_loc_error'][2])\n",
    "    holt_k_rg = np.append(holt_k_rg, res['k_rg_error'][2])\n",
    "    holt_spat_burst = np.append(holt_spat_burst, res['spat_burst_error'][2])\n",
    "    holt_rand_entr = np.append(holt_rand_entr, res['rand_entr_error'][2])\n",
    "    holt_real_entr = np.append(holt_real_entr, res['real_entr_error'][2])\n",
    "    holt_uncorr_entr = np.append(holt_uncorr_entr, res['uncorr_entr_error'][2])\n",
    "    holt_mae = np.append(holt_mae, res['mae'][2])\n",
    "    es_rec = np.append(es_rec, res['recency'][3])\n",
    "    es_freq = np.append(es_freq, res['freq_rank'][3])\n",
    "    es_no_loc = np.append(es_no_loc, res['no_loc_error'][3])\n",
    "    es_k_rg = np.append(es_k_rg, res['k_rg_error'][3])\n",
    "    es_spat_burst = np.append(es_spat_burst, res['spat_burst_error'][3])\n",
    "    es_rand_entr = np.append(es_rand_entr, res['rand_entr_error'][3])\n",
    "    es_real_entr = np.append(es_real_entr, res['real_entr_error'][3])\n",
    "    es_uncorr_entr = np.append(es_uncorr_entr, res['uncorr_entr_error'][3])\n",
    "    es_mae = np.append(es_mae, res['mae'][3])\n",
    "    arima_rec = np.append(arima_rec, res['recency'][4])\n",
    "    arima_freq = np.append(arima_freq, res['freq_rank'][4])\n",
    "    arima_no_loc = np.append(arima_no_loc, res['no_loc_error'][4])\n",
    "    arima_k_rg = np.append(arima_k_rg, res['k_rg_error'][4])\n",
    "    arima_spat_burst = np.append(arima_spat_burst, res['spat_burst_error'][4])\n",
    "    arima_rand_entr = np.append(arima_rand_entr, res['rand_entr_error'][4])\n",
    "    arima_real_entr = np.append(arima_real_entr, res['real_entr_error'][4])\n",
    "    arima_uncorr_entr = np.append(arima_uncorr_entr, res['uncorr_entr_error'][4])\n",
    "    arima_mae = np.append(arima_mae, res['mae'][4])\n",
    "    sarima_rec = np.append(sarima_rec, res['recency'][5])\n",
    "    sarima_freq = np.append(sarima_freq, res['freq_rank'][5])\n",
    "    sarima_no_loc = np.append(sarima_no_loc, res['no_loc_error'][5])\n",
    "    sarima_k_rg = np.append(sarima_k_rg, res['k_rg_error'][5])\n",
    "    sarima_spat_burst = np.append(sarima_spat_burst, res['spat_burst_error'][5])\n",
    "    sarima_rand_entr = np.append(sarima_rand_entr, res['rand_entr_error'][5])\n",
    "    sarima_real_entr = np.append(sarima_real_entr, res['real_entr_error'][5])\n",
    "    sarima_uncorr_entr = np.append(sarima_uncorr_entr, res['uncorr_entr_error'][5])\n",
    "    sarima_mae = np.append(sarima_mae, res['mae'][5])\n",
    "    li_rec = np.append(li_rec, res['recency'][6])\n",
    "    li_freq = np.append(li_freq, res['freq_rank'][6])\n",
    "    li_no_loc = np.append(li_no_loc, res['no_loc_error'][6])\n",
    "    li_k_rg = np.append(li_k_rg, res['k_rg_error'][6])\n",
    "    li_spat_burst = np.append(li_spat_burst, res['spat_burst_error'][6])\n",
    "    li_rand_entr = np.append(li_rand_entr, res['rand_entr_error'][6])\n",
    "    li_real_entr = np.append(li_real_entr, res['real_entr_error'][6])\n",
    "    li_uncorr_entr = np.append(li_uncorr_entr, res['uncorr_entr_error'][6])\n",
    "    li_mae = np.append(li_mae, res['mae'][6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the average value of the metrics for each method\n",
    "avg_rec = np.array([np.mean(mtgp_rec), np.mean(ses_rec), np.mean(holt_rec), np.mean(es_rec), np.mean(arima_rec), np.mean(sarima_rec), np.mean(li_rec)])\n",
    "avg_freq = np.array([np.mean(mtgp_freq), np.mean(ses_freq), np.mean(holt_freq), np.mean(es_freq), np.mean(arima_freq), np.mean(sarima_freq), np.mean(li_freq)])\n",
    "avg_no_loc = np.array([np.mean(mtgp_no_loc), np.mean(ses_no_loc), np.mean(holt_no_loc), np.mean(es_no_loc), np.mean(arima_no_loc), np.mean(sarima_no_loc), np.mean(li_no_loc)])\n",
    "avg_k_rg = np.array([np.mean(mtgp_k_rg), np.mean(ses_k_rg), np.mean(holt_k_rg), np.mean(es_k_rg), np.mean(arima_k_rg), np.mean(sarima_k_rg), np.mean(li_k_rg)])\n",
    "avg_spat_burst = np.array([np.mean(mtgp_spat_burst), np.mean(ses_spat_burst), np.mean(holt_spat_burst), np.mean(es_spat_burst), np.mean(arima_spat_burst), np.mean(sarima_spat_burst), np.mean(li_spat_burst)])\n",
    "avg_rand_entr = np.array([np.mean(mtgp_rand_entr), np.mean(ses_rand_entr), np.mean(holt_rand_entr), np.mean(es_rand_entr), np.mean(arima_rand_entr), np.mean(sarima_rand_entr), np.mean(li_rand_entr)])\n",
    "avg_real_entr = np.array([np.mean(mtgp_real_entr), np.mean(ses_real_entr), np.mean(holt_real_entr), np.mean(es_real_entr), np.mean(arima_real_entr), np.mean(sarima_real_entr), np.mean(li_real_entr)])\n",
    "avg_uncorr_entr = np.array([np.mean(mtgp_uncorr_entr), np.mean(ses_uncorr_entr), np.mean(holt_uncorr_entr), np.mean(es_uncorr_entr), np.mean(arima_uncorr_entr), np.mean(sarima_uncorr_entr), np.mean(li_uncorr_entr)])\n",
    "\n",
    "# Get the standard deviation of the metrics for each method\n",
    "std_rec = np.array([np.std(mtgp_rec), np.std(ses_rec), np.std(holt_rec), np.std(es_rec), np.std(arima_rec), np.std(sarima_rec), np.std(li_rec)])\n",
    "std_freq = np.array([np.std(mtgp_freq), np.std(ses_freq), np.std(holt_freq), np.std(es_freq), np.std(arima_freq), np.std(sarima_freq), np.std(li_freq)])\n",
    "std_no_loc = np.array([np.std(mtgp_no_loc), np.std(ses_no_loc), np.std(holt_no_loc), np.std(es_no_loc), np.std(arima_no_loc), np.std(sarima_no_loc), np.std(li_no_loc)])\n",
    "std_k_rg = np.array([np.std(mtgp_k_rg), np.std(ses_k_rg), np.std(holt_k_rg), np.std(es_k_rg), np.std(arima_k_rg), np.std(sarima_k_rg), np.std(li_k_rg)])\n",
    "std_spat_burst = np.array([np.std(mtgp_spat_burst), np.std(ses_spat_burst), np.std(holt_spat_burst), np.std(es_spat_burst), np.std(arima_spat_burst), np.std(sarima_spat_burst), np.std(li_spat_burst)])\n",
    "std_rand_entr = np.array([np.std(mtgp_rand_entr), np.std(ses_rand_entr), np.std(holt_rand_entr), np.std(es_rand_entr), np.std(arima_rand_entr), np.std(sarima_rand_entr), np.std(li_rand_entr)])\n",
    "std_real_entr = np.array([np.std(mtgp_real_entr), np.std(ses_real_entr), np.std(holt_real_entr), np.std(es_real_entr), np.std(arima_real_entr), np.std(sarima_real_entr), np.std(li_real_entr)])\n",
    "std_uncorr_entr = np.array([np.std(mtgp_uncorr_entr), np.std(ses_uncorr_entr), np.std(holt_uncorr_entr), np.std(es_uncorr_entr), np.std(arima_uncorr_entr), np.std(sarima_uncorr_entr), np.std(li_uncorr_entr)])\n",
    "\n",
    "# Put averages into a dataframe\n",
    "df_15_skmob = pd.DataFrame({'Method': ['MTGP', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX', 'LI'],\n",
    "                     'Recency ranking accuracy': avg_rec,\n",
    "                        'Frequency ranking accuracy': avg_freq,\n",
    "                        'Number of locations error': avg_no_loc,\n",
    "                        'Radius of gyration error': avg_k_rg,\n",
    "                        'Real entropy error': avg_real_entr,\n",
    "                        'Random entropy error': avg_rand_entr,\n",
    "                        'Uncorrelated entropy error': avg_uncorr_entr})\n",
    "\n",
    "df_15_skmob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycle through each file and save results as a numpy array\n",
    "folderpath=\"C:\\\\Users\\\\ekino\\\\OneDrive - UW\\\\GPR\\\\Results\\\\1\\\\all_skmob_metrics\"\n",
    "os.chdir(folderpath)\n",
    "all_file_num=len(glob.glob(\"*.csv\"))\n",
    "print(\"There are\", all_file_num, \"files in the folder\")\n",
    "\n",
    "mtgp_rec = np.array([])\n",
    "mtgp_freq = np.array([])\n",
    "mtgp_no_loc = np.array([])\n",
    "mtgp_k_rg = np.array([])\n",
    "mtgp_spat_burst = np.array([])\n",
    "mtgp_rand_entr = np.array([])\n",
    "mtgp_real_entr = np.array([])\n",
    "mtgp_uncorr_entr = np.array([])\n",
    "mtgp_mae = np.array([])\n",
    "ses_rec = np.array([])\n",
    "ses_freq = np.array([])\n",
    "ses_no_loc = np.array([])\n",
    "ses_k_rg = np.array([])\n",
    "ses_spat_burst = np.array([])\n",
    "ses_rand_entr = np.array([])\n",
    "ses_real_entr = np.array([])\n",
    "ses_uncorr_entr = np.array([])\n",
    "ses_mae = np.array([])\n",
    "holt_rec = np.array([])\n",
    "holt_freq = np.array([])\n",
    "holt_no_loc = np.array([])\n",
    "holt_k_rg = np.array([])\n",
    "holt_spat_burst = np.array([])\n",
    "holt_rand_entr = np.array([])\n",
    "holt_real_entr = np.array([])\n",
    "holt_uncorr_entr = np.array([])\n",
    "holt_mae = np.array([])\n",
    "es_rec = np.array([])\n",
    "es_freq = np.array([])\n",
    "es_no_loc = np.array([])\n",
    "es_k_rg = np.array([])\n",
    "es_spat_burst = np.array([])\n",
    "es_rand_entr = np.array([])\n",
    "es_real_entr = np.array([])\n",
    "es_uncorr_entr = np.array([])\n",
    "es_mae = np.array([])\n",
    "arima_rec = np.array([])\n",
    "arima_freq = np.array([])\n",
    "arima_no_loc = np.array([])\n",
    "arima_k_rg = np.array([])\n",
    "arima_spat_burst = np.array([])\n",
    "arima_rand_entr = np.array([])\n",
    "arima_real_entr = np.array([])\n",
    "arima_uncorr_entr = np.array([])\n",
    "arima_mae = np.array([])\n",
    "sarima_rec = np.array([])\n",
    "sarima_freq = np.array([])\n",
    "sarima_no_loc = np.array([])\n",
    "sarima_k_rg = np.array([])\n",
    "sarima_spat_burst = np.array([])\n",
    "sarima_rand_entr = np.array([])\n",
    "sarima_real_entr = np.array([])\n",
    "sarima_uncorr_entr = np.array([])\n",
    "sarima_mae = np.array([])\n",
    "li_rec = np.array([])\n",
    "li_freq = np.array([])\n",
    "li_no_loc = np.array([])\n",
    "li_k_rg = np.array([])\n",
    "li_spat_burst = np.array([])\n",
    "li_rand_entr = np.array([])\n",
    "li_real_entr = np.array([])\n",
    "li_uncorr_entr = np.array([])\n",
    "li_mae = np.array([])\n",
    "\n",
    "\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    res = pd.read_csv(file, header=0)\n",
    "    # Store each metric in a numpy array\n",
    "    mtgp_rec = np.append(mtgp_rec, res['recency'][0])\n",
    "    mtgp_freq = np.append(mtgp_freq, res['freq_rank'][0])\n",
    "    mtgp_no_loc = np.append(mtgp_no_loc, res['no_loc_error'][0])\n",
    "    mtgp_k_rg = np.append(mtgp_k_rg, res['k_rg_error'][0])\n",
    "    mtgp_spat_burst = np.append(mtgp_spat_burst, res['spat_burst_error'][0])\n",
    "    mtgp_rand_entr = np.append(mtgp_rand_entr, res['rand_entr_error'][0])\n",
    "    mtgp_real_entr = np.append(mtgp_real_entr, res['real_entr_error'][0])\n",
    "    mtgp_uncorr_entr = np.append(mtgp_uncorr_entr, res['uncorr_entr_error'][0])\n",
    "    mtgp_mae = np.append(mtgp_mae, res['mae'][0])\n",
    "    ses_rec = np.append(ses_rec, res['recency'][1])\n",
    "    ses_freq = np.append(ses_freq, res['freq_rank'][1])\n",
    "    ses_no_loc = np.append(ses_no_loc, res['no_loc_error'][1])\n",
    "    ses_k_rg = np.append(ses_k_rg, res['k_rg_error'][1])\n",
    "    ses_spat_burst = np.append(ses_spat_burst, res['spat_burst_error'][1])\n",
    "    ses_rand_entr = np.append(ses_rand_entr, res['rand_entr_error'][1])\n",
    "    ses_real_entr = np.append(ses_real_entr, res['real_entr_error'][1])\n",
    "    ses_uncorr_entr = np.append(ses_uncorr_entr, res['uncorr_entr_error'][1])\n",
    "    ses_mae = np.append(ses_mae, res['mae'][1])\n",
    "    holt_rec = np.append(holt_rec, res['recency'][2])\n",
    "    holt_freq = np.append(holt_freq, res['freq_rank'][2])\n",
    "    holt_no_loc = np.append(holt_no_loc, res['no_loc_error'][2])\n",
    "    holt_k_rg = np.append(holt_k_rg, res['k_rg_error'][2])\n",
    "    holt_spat_burst = np.append(holt_spat_burst, res['spat_burst_error'][2])\n",
    "    holt_rand_entr = np.append(holt_rand_entr, res['rand_entr_error'][2])\n",
    "    holt_real_entr = np.append(holt_real_entr, res['real_entr_error'][2])\n",
    "    holt_uncorr_entr = np.append(holt_uncorr_entr, res['uncorr_entr_error'][2])\n",
    "    holt_mae = np.append(holt_mae, res['mae'][2])\n",
    "    es_rec = np.append(es_rec, res['recency'][3])\n",
    "    es_freq = np.append(es_freq, res['freq_rank'][3])\n",
    "    es_no_loc = np.append(es_no_loc, res['no_loc_error'][3])\n",
    "    es_k_rg = np.append(es_k_rg, res['k_rg_error'][3])\n",
    "    es_spat_burst = np.append(es_spat_burst, res['spat_burst_error'][3])\n",
    "    es_rand_entr = np.append(es_rand_entr, res['rand_entr_error'][3])\n",
    "    es_real_entr = np.append(es_real_entr, res['real_entr_error'][3])\n",
    "    es_uncorr_entr = np.append(es_uncorr_entr, res['uncorr_entr_error'][3])\n",
    "    es_mae = np.append(es_mae, res['mae'][3])\n",
    "    arima_rec = np.append(arima_rec, res['recency'][4])\n",
    "    arima_freq = np.append(arima_freq, res['freq_rank'][4])\n",
    "    arima_no_loc = np.append(arima_no_loc, res['no_loc_error'][4])\n",
    "    arima_k_rg = np.append(arima_k_rg, res['k_rg_error'][4])\n",
    "    arima_spat_burst = np.append(arima_spat_burst, res['spat_burst_error'][4])\n",
    "    arima_rand_entr = np.append(arima_rand_entr, res['rand_entr_error'][4])\n",
    "    arima_real_entr = np.append(arima_real_entr, res['real_entr_error'][4])\n",
    "    arima_uncorr_entr = np.append(arima_uncorr_entr, res['uncorr_entr_error'][4])\n",
    "    arima_mae = np.append(arima_mae, res['mae'][4])\n",
    "    sarima_rec = np.append(sarima_rec, res['recency'][5])\n",
    "    sarima_freq = np.append(sarima_freq, res['freq_rank'][5])\n",
    "    sarima_no_loc = np.append(sarima_no_loc, res['no_loc_error'][5])\n",
    "    sarima_k_rg = np.append(sarima_k_rg, res['k_rg_error'][5])\n",
    "    sarima_spat_burst = np.append(sarima_spat_burst, res['spat_burst_error'][5])\n",
    "    sarima_rand_entr = np.append(sarima_rand_entr, res['rand_entr_error'][5])\n",
    "    sarima_real_entr = np.append(sarima_real_entr, res['real_entr_error'][5])\n",
    "    sarima_uncorr_entr = np.append(sarima_uncorr_entr, res['uncorr_entr_error'][5])\n",
    "    sarima_mae = np.append(sarima_mae, res['mae'][5])\n",
    "    li_rec = np.append(li_rec, res['recency'][6])\n",
    "    li_freq = np.append(li_freq, res['freq_rank'][6])\n",
    "    li_no_loc = np.append(li_no_loc, res['no_loc_error'][6])\n",
    "    li_k_rg = np.append(li_k_rg, res['k_rg_error'][6])\n",
    "    li_spat_burst = np.append(li_spat_burst, res['spat_burst_error'][6])\n",
    "    li_rand_entr = np.append(li_rand_entr, res['rand_entr_error'][6])\n",
    "    li_real_entr = np.append(li_real_entr, res['real_entr_error'][6])\n",
    "    li_uncorr_entr = np.append(li_uncorr_entr, res['uncorr_entr_error'][6])\n",
    "    li_mae = np.append(li_mae, res['mae'][6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the average value of the metrics for each method\n",
    "avg_rec = np.array([np.mean(mtgp_rec), np.mean(ses_rec), np.mean(holt_rec), np.mean(es_rec), np.mean(arima_rec), np.mean(sarima_rec), np.mean(li_rec)])\n",
    "avg_freq = np.array([np.mean(mtgp_freq), np.mean(ses_freq), np.mean(holt_freq), np.mean(es_freq), np.mean(arima_freq), np.mean(sarima_freq), np.mean(li_freq)])\n",
    "avg_no_loc = np.array([np.mean(mtgp_no_loc), np.mean(ses_no_loc), np.mean(holt_no_loc), np.mean(es_no_loc), np.mean(arima_no_loc), np.mean(sarima_no_loc), np.mean(li_no_loc)])\n",
    "avg_k_rg = np.array([np.mean(mtgp_k_rg), np.mean(ses_k_rg), np.mean(holt_k_rg), np.mean(es_k_rg), np.mean(arima_k_rg), np.mean(sarima_k_rg), np.mean(li_k_rg)])\n",
    "avg_spat_burst = np.array([np.mean(mtgp_spat_burst), np.mean(ses_spat_burst), np.mean(holt_spat_burst), np.mean(es_spat_burst), np.mean(arima_spat_burst), np.mean(sarima_spat_burst), np.mean(li_spat_burst)])\n",
    "avg_rand_entr = np.array([np.mean(mtgp_rand_entr), np.mean(ses_rand_entr), np.mean(holt_rand_entr), np.mean(es_rand_entr), np.mean(arima_rand_entr), np.mean(sarima_rand_entr), np.mean(li_rand_entr)])\n",
    "avg_real_entr = np.array([np.mean(mtgp_real_entr), np.mean(ses_real_entr), np.mean(holt_real_entr), np.mean(es_real_entr), np.mean(arima_real_entr), np.mean(sarima_real_entr), np.mean(li_real_entr)])\n",
    "avg_uncorr_entr = np.array([np.mean(mtgp_uncorr_entr), np.mean(ses_uncorr_entr), np.mean(holt_uncorr_entr), np.mean(es_uncorr_entr), np.mean(arima_uncorr_entr), np.mean(sarima_uncorr_entr), np.mean(li_uncorr_entr)])\n",
    "\n",
    "# Get the standard deviation of the metrics for each method\n",
    "std_rec = np.array([np.std(mtgp_rec), np.std(ses_rec), np.std(holt_rec), np.std(es_rec), np.std(arima_rec), np.std(sarima_rec), np.std(li_rec)])\n",
    "std_freq = np.array([np.std(mtgp_freq), np.std(ses_freq), np.std(holt_freq), np.std(es_freq), np.std(arima_freq), np.std(sarima_freq), np.std(li_freq)])\n",
    "std_no_loc = np.array([np.std(mtgp_no_loc), np.std(ses_no_loc), np.std(holt_no_loc), np.std(es_no_loc), np.std(arima_no_loc), np.std(sarima_no_loc), np.std(li_no_loc)])\n",
    "std_k_rg = np.array([np.std(mtgp_k_rg), np.std(ses_k_rg), np.std(holt_k_rg), np.std(es_k_rg), np.std(arima_k_rg), np.std(sarima_k_rg), np.std(li_k_rg)])\n",
    "std_spat_burst = np.array([np.std(mtgp_spat_burst), np.std(ses_spat_burst), np.std(holt_spat_burst), np.std(es_spat_burst), np.std(arima_spat_burst), np.std(sarima_spat_burst), np.std(li_spat_burst)])\n",
    "std_rand_entr = np.array([np.std(mtgp_rand_entr), np.std(ses_rand_entr), np.std(holt_rand_entr), np.std(es_rand_entr), np.std(arima_rand_entr), np.std(sarima_rand_entr), np.std(li_rand_entr)])\n",
    "std_real_entr = np.array([np.std(mtgp_real_entr), np.std(ses_real_entr), np.std(holt_real_entr), np.std(es_real_entr), np.std(arima_real_entr), np.std(sarima_real_entr), np.std(li_real_entr)])\n",
    "std_uncorr_entr = np.array([np.std(mtgp_uncorr_entr), np.std(ses_uncorr_entr), np.std(holt_uncorr_entr), np.std(es_uncorr_entr), np.std(arima_uncorr_entr), np.std(sarima_uncorr_entr), np.std(li_uncorr_entr)])\n",
    "\n",
    "# Put averages into a dataframe\n",
    "df_1_skmob = pd.DataFrame({'Method': ['MTGP', 'SES', 'Holt', 'ES', 'ARIMA', 'SARIMAX', 'LI'],\n",
    "                     'Recency ranking accuracy': avg_rec,\n",
    "                        'Frequency ranking accuracy': avg_freq,\n",
    "                        'Number of locations error': avg_no_loc,\n",
    "                        'Radius of gyration error': avg_k_rg,\n",
    "                        'Real entropy error': avg_real_entr,\n",
    "                        'Random entropy error': avg_rand_entr,\n",
    "                        'Uncorrelated entropy error': avg_uncorr_entr})\n",
    "\n",
    "df_1_skmob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find equally weighted average of all skmob metric dataframes\n",
    "df_sum = df_15_skmob + df_30_skmob + df_60_skmob + df_360_skmob + df_1440_skmob + df_10080_skmob\n",
    "\n",
    "# Discard first column\n",
    "df_sum = df_sum.iloc[:, 1:]\n",
    "\n",
    "# Divide by 6 to get equally weighted average\n",
    "df_avg = df_sum/6\n",
    "\n",
    "df_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg.to_csv('aggregated_skmob_metrics/avg_skmob.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory \"aggregated skmob metric results\" if it does not exist\n",
    "if not os.path.exists('aggregated_skmob_metrics'):\n",
    "    os.makedirs('aggregated_skmob_metrics')\n",
    "\n",
    "# Save the dataframes to csv files\n",
    "df_15_skmob.to_csv('aggregated_skmob_metrics/15_skmob.csv', index=False)\n",
    "df_30_skmob.to_csv('aggregated_skmob_metrics/30_skmob.csv', index=False)\n",
    "df_60_skmob.to_csv('aggregated_skmob_metrics/60_skmob.csv', index=False)\n",
    "df_360_skmob.to_csv('aggregated_skmob_metrics/360_skmob.csv', index=False)\n",
    "df_1440_skmob.to_csv('aggregated_skmob_metrics/1440_skmob.csv', index=False)\n",
    "df_10080_skmob.to_csv('aggregated_skmob_metrics/10080_skmob.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rog_curve = [df_15_skmob['Radius of gyration error'][0], df_30_skmob['Radius of gyration error'][0], df_60_skmob['Radius of gyration error'][0], df_360_skmob['Radius of gyration error'][0], df_1440_skmob['Radius of gyration error'][0], df_10080_skmob['Radius of gyration error'][0]]\n",
    "rec_curve = [df_15_skmob['Recency ranking accuracy'][0], df_30_skmob['Recency ranking accuracy'][0], df_60_skmob['Recency ranking accuracy'][0], df_360_skmob['Recency ranking accuracy'][0], df_1440_skmob['Recency ranking accuracy'][0], df_10080_skmob['Recency ranking accuracy'][0]]\n",
    "freq_curve = [df_15_skmob['Frequency ranking accuracy'][0], df_30_skmob['Frequency ranking accuracy'][0], df_60_skmob['Frequency ranking accuracy'][0], df_360_skmob['Frequency ranking accuracy'][0], df_1440_skmob['Frequency ranking accuracy'][0], df_10080_skmob['Frequency ranking accuracy'][0]]\n",
    "no_loc_curve = [df_15_skmob['Number of locations error'][0], df_30_skmob['Number of locations error'][0], df_60_skmob['Number of locations error'][0], df_360_skmob['Number of locations error'][0], df_1440_skmob['Number of locations error'][0], df_10080_skmob['Number of locations error'][0]]\n",
    "real_entr_curve = [df_15_skmob['Real entropy error'][0], df_30_skmob['Real entropy error'][0], df_60_skmob['Real entropy error'][0], df_360_skmob['Real entropy error'][0], df_1440_skmob['Real entropy error'][0], df_10080_skmob['Real entropy error'][0]]\n",
    "rand_entr_curve = [df_15_skmob['Random entropy error'][0], df_30_skmob['Random entropy error'][0], df_60_skmob['Random entropy error'][0], df_360_skmob['Random entropy error'][0], df_1440_skmob['Random entropy error'][0], df_10080_skmob['Random entropy error'][0]]\n",
    "uncorr_entr_curve = [df_15_skmob['Uncorrelated entropy error'][0], df_30_skmob['Uncorrelated entropy error'][0], df_60_skmob['Uncorrelated entropy error'][0], df_360_skmob['Uncorrelated entropy error'][0], df_1440_skmob['Uncorrelated entropy error'][0], df_10080_skmob['Uncorrelated entropy error'][0]]\n",
    "\n",
    "\n",
    "# Normalize the no_loc_curve such that the maximum value is 1\n",
    "no_loc_curve = no_loc_curve/np.min(no_loc_curve)\n",
    "\n",
    "# Plot curves with respect to the bin size\n",
    "# Do absolute value of error\n",
    "# Use log scale for x-axis\n",
    "# Use separate plots for recency and frequency\n",
    "\n",
    "plt.plot([15, 30, 60, 360, 1440, 10080], np.abs(rog_curve), label='Radius of gyration error')\n",
    "plt.plot([15, 30, 60, 360, 1440, 10080], np.abs(rec_curve), label='Recency ranking accuracy')\n",
    "plt.plot([15, 30, 60, 360, 1440, 10080], np.abs(freq_curve), label='Frequency ranking accuracy')\n",
    "plt.plot([15, 30, 60, 360, 1440, 10080], np.abs(no_loc_curve), label='Number of locations error')\n",
    "plt.plot([15, 30, 60, 360, 1440, 10080], np.abs(real_entr_curve), label='Real entropy error')\n",
    "plt.plot([15, 30, 60, 360, 1440, 10080], np.abs(rand_entr_curve), label='Random entropy error')\n",
    "plt.plot([15, 30, 60, 360, 1440, 10080], np.abs(uncorr_entr_curve), label='Uncorrelated entropy error')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Gap length (minutes)')\n",
    "plt.ylabel('Error')\n",
    "# Put legend to the right of plot\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_loc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([15, 30, 60, 360, 1440, 10080], np.abs(rec_curve), label='Recency ranking accuracy')\n",
    "plt.plot([15, 30, 60, 360, 1440, 10080], np.abs(freq_curve), label='Frequency ranking accuracy')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Gap length (minutes)')\n",
    "plt.ylabel('Error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skmob_alt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3be6a4b976e3fc5992cbda345f874ed08629b5aa1a879cf1954f33c2638a941f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
