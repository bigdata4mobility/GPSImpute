{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import mobileDataToolkit.analysis as analysis\n",
    "from numba import cuda\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To-Do: Parallelize this with CUDA to save days"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further To-Do: obtain the following graphs from the data\n",
    "* Temporal daily distribution of observations (Fig 6)\n",
    "* Time interval distribution between two consecutive observations (Fig 3)\n",
    "* Cumulative distribution of location accuracy (Fig 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderpath=\"C:/Users/ekino/UW/cis_bigdata2021 - Seattle_2000/Seattle_2000_in_2020/Seattle_2000/\"\n",
    "os.chdir(folderpath)\n",
    "cnt=0\n",
    "all_file_num=len(glob.glob(\"*.csv\"))\n",
    "\n",
    "binlens = [10080*60, 1440*60, 360*60, 60*60]\n",
    "oneweek = np.array([])\n",
    "oneday = np.array([])\n",
    "sixhours = np.array([])\n",
    "onehour = np.array([])\n",
    "diff = np.array([])\n",
    "loc_acc = np.array([])\n",
    "\n",
    "# Create dataframe to store temporal distribution\n",
    "temp_distribution = pd.DataFrame(columns=['timestamp', 'unix_min', 'day'])\n",
    "\n",
    "#for i in binlens:\n",
    "#    print(\"Start bin length: \", i, \" seconds\")\n",
    "for file in glob.glob(\"*.csv\"):\n",
    "    Suball = pd.read_csv(folderpath+file,header=0)\n",
    "    Suball['timestamp'] = pd.to_datetime(Suball['timestamp'])\n",
    "    Suball['unix_min'] = Suball['timestamp'].astype(np.int64) // 10**9\n",
    "    Suball = Suball.sort_values(by=['unix_min'])\n",
    "\n",
    "    # Obtain difference between consecutive timestamps\n",
    "    Suball['diff'] = Suball['unix_min'].diff()\n",
    "    diff = np.append(diff, Suball['diff'])\n",
    "\n",
    "    # Day of the week, in words\n",
    "    Suball['day'] = Suball['timestamp'].dt.day_name()\n",
    "\n",
    "    # Add to dataframe the relevant columns\n",
    "    temp_distribution = pd.concat((temp_distribution, Suball[['timestamp', 'unix_min', 'day']]))\n",
    "\n",
    "    # Add location accuracy\n",
    "    loc_acc = np.append(loc_acc, Suball['precision'])\n",
    "\n",
    "    # Count number of rows with 'diff' > i\n",
    "    # cnt = Suball[Suball['diff'] > i].shape[0]\n",
    "    #print(\"Number of rows with 'diff' > \", i, \" seconds: \", cnt)\n",
    "    \n",
    "    #tempocp = analysis.tempOcp(Suball, unix_col = 'unix_min', bin_len = i)\n",
    "    #print(\"temporal occupancy: \", tempocp)\n",
    "    \"\"\" if i == 10080*60:\n",
    "        oneweek = np.append(oneweek, cnt)\n",
    "    elif i == 1440*60:\n",
    "        oneday = np.append(oneday, cnt)\n",
    "    elif i == 360*60:\n",
    "        sixhours = np.append(sixhours, cnt)\n",
    "    elif i == 60*60:\n",
    "        onehour = np.append(onehour, cnt) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create continuous scatterplot of observations through each hour of the day\n",
    "# Create hour column\n",
    "temp_distribution['hour'] = temp_distribution['timestamp'].dt.hour\n",
    "\n",
    "# Create monotonically-increasing 10-minute bins of the day\n",
    "temp_distribution['10_min_bin'] = temp_distribution['hour'] * 6 + temp_distribution['timestamp'].dt.minute // 10\n",
    "\n",
    "# Groupby hour and day\n",
    "temp_distribution_grouped = temp_distribution.groupby(['10_min_bin', 'day']).size().reset_index(name='count')\n",
    "\n",
    "# Order by day of the week\n",
    "temp_distribution_grouped['day'] = pd.Categorical(temp_distribution_grouped['day'], categories=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make 10x20 figure\n",
    "plt.figure(figsize=(10, 5))\n",
    "# Create continuous scatterplot, use small points to avoid overlapping\n",
    "sns.scatterplot(data=temp_distribution_grouped, x='10_min_bin', y='count', hue='day', s=9)\n",
    "# Skip every other x-axis label\n",
    "plt.xticks(np.arange(0, 144, 12), np.arange(0, 24, 2))\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Number of observations')\n",
    "# No legend title\n",
    "plt.legend(title=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save figure configurations, make it a lineplot with different types of lines\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.lineplot(data=temp_distribution_grouped, x='10_min_bin', y='count', hue='day', style='day',dashes=True)\n",
    "plt.xticks(np.arange(0, 144, 12), np.arange(0, 24, 2))\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Number of observations')\n",
    "plt.legend(title=None)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Location Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NAN values for loc acc\n",
    "loc_acc = loc_acc[~np.isnan(loc_acc)]\n",
    "\n",
    "# Drop the lowest 1 and 99 percentile of location accuracy\n",
    "loc_acc = loc_acc[(loc_acc > np.percentile(loc_acc, 1)) & (loc_acc < np.percentile(loc_acc, 99))]\n",
    "\n",
    "# Create cumulative distribution of location accuracy\n",
    "loc_acc_sorted = np.sort(loc_acc)\n",
    "\n",
    "p = 1. * np.arange(len(loc_acc_sorted)) / (len(loc_acc_sorted) - 1)\n",
    "\n",
    "# Create cumulative distribution\n",
    "loc_acc_cum = np.cumsum(loc_acc_sorted) / np.sum(loc_acc_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CDF of location accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(loc_acc_sorted, p)\n",
    "plt.ylabel('Percentile (%)')\n",
    "# Make y-axis percentages\n",
    "plt.yticks(np.arange(0, 1.1, 0.1), np.arange(0, 110, 10))\n",
    "# Show until 400 meters\n",
    "plt.xlim(0, 400)\n",
    "plt.xlabel('Location accuracy (m)')\n",
    "# Grid\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25th percentile of location accuracy\n",
    "print(\"25th percentile of location accuracy: \", np.percentile(loc_acc, 25))\n",
    "\n",
    "# 50th percentile of location accuracy\n",
    "print(\"50th percentile of location accuracy: \", np.percentile(loc_acc, 50))\n",
    "\n",
    "# 75th percentile of location accuracy\n",
    "print(\"75th percentile of location accuracy: \", np.percentile(loc_acc, 75))\n",
    "\n",
    "# 81st percentile of location accuracy\n",
    "print(\"81st percentile of location accuracy: \", np.percentile(loc_acc, 82))\n",
    "\n",
    "# 95th percentile of location accuracy\n",
    "print(\"95th percentile of location accuracy: \", np.percentile(loc_acc, 95))\n",
    "\n",
    "# 98th percentile of location accuracy\n",
    "print(\"98th percentile of location accuracy: \", np.percentile(loc_acc, 98))\n",
    "\n",
    "# 99th percentile of location accuracy\n",
    "print(\"99th percentile of location accuracy: \", np.percentile(loc_acc, 99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe diff, non scientific notation\n",
    "print(\"Describe diff: \", pd.DataFrame(diff).describe().to_string(float_format=lambda x: '%.3f' % x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nan values for diff\n",
    "diff = diff[~np.isnan(diff)]\n",
    "\n",
    "# Drop maximum value for diff\n",
    "diff = diff[diff != np.max(diff)]\n",
    "\n",
    "# Drop the top 2% of values for diff\n",
    "diff = diff[diff < np.percentile(diff, 99)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of diff, but have percent on y-axis, have a log scale on x-axis\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(diff, bins=10000, density=True)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Difference between consecutive timestamps (seconds)')\n",
    "plt.ylabel('Percent of observations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of diff\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(diff, bins=1000)\n",
    "plt.xlabel('Difference between consecutive timestamps (seconds)')\n",
    "plt.ylabel('Number of observations')\n",
    "# Limit to 1500 seconds\n",
    "plt.xlim(-10, 1500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single entry function\n",
    "@cuda.jit(device=True)\n",
    "def s(Suball, i, \n",
    "      oneweek = np.array([]), \n",
    "\t  oneday = np.array([]), \n",
    "\t  sixhours = np.array([]), \n",
    "\t  onehour = np.array([]), \n",
    "\t  diff = np.array([]), \n",
    "\t  loc_acc = np.array([]), \n",
    "\t  temp_distribution = pd.DataFrame(columns=['timestamp', 'unix_min', 'day'])):\t\n",
    "\tSuball['timestamp'] = pd.to_datetime(Suball['timestamp'])\n",
    "\tSuball['unix_min'] = Suball['timestamp'].astype(np.int64) // 10**9\n",
    "\tSuball = Suball.sort_values(by=['unix_min'])\n",
    "\n",
    "\t# Obtain difference between consecutive timestamps\n",
    "\tSuball['diff'] = Suball['unix_min'].diff()\n",
    "\tdiff = np.append(diff, Suball['diff'])\n",
    "\n",
    "\t# Day of the week, in words\n",
    "\tSuball['day'] = Suball['timestamp'].dt.day_name()\n",
    "\n",
    "\t# Add to dataframe the relevant columns\n",
    "\ttemp_distribution = pd.concat((temp_distribution, Suball[['timestamp', 'unix_min', 'day']]))\n",
    "\n",
    "\t# Add location accuracy\n",
    "\tloc_acc = np.append(loc_acc, Suball['precision'])\n",
    "\n",
    "\t# Count number of rows with 'diff' > i\n",
    "\tcnt = Suball[Suball['diff'] > i].shape[0]\n",
    "\n",
    "\tif i == 10080*60:\n",
    "\t\toneweek = np.append(oneweek, cnt)\n",
    "\telif i == 1440*60:\n",
    "\t\toneday = np.append(oneday, cnt)\n",
    "\telif i == 360*60:\n",
    "\t\tsixhours = np.append(sixhours, cnt)\n",
    "\telif i == 60*60:\n",
    "\t\tonehour = np.append(onehour, cnt)\n",
    "\n",
    "@cuda.jit\n",
    "def s_kernel(d_x, i):\n",
    "\tn = d_x.shape[0]\n",
    "\tj = cuda.grid(1)\n",
    "\tif j < n:\n",
    "\t\td_x[j] = s(d_x[j], i)\n",
    "\t\n",
    "def sArray(x):\n",
    "\tn = x.shape[0]\n",
    "\td_x = cuda.to_device(x) # d_ means the device side copy of the array\n",
    "\td_f = cuda.device_array_like(d_x) # allocate device array for f\n",
    "\tblockDims = TBP\n",
    "\tgridDims = (n + blockDims - 1) // blockDims\n",
    "\ts_kernel[gridDims, blockDims](d_f, d_x)\n",
    "\treturn d_f.copy_to_host() # copy result back to host\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderpath=\"C:/Users/ekino/UW/cis_bigdata2021 - Seattle_2000/Seattle_2000_in_2020/Seattle_2000/\"\n",
    "os.chdir(folderpath)\n",
    "cnt=0\n",
    "all_file_num=len(glob.glob(\"*.csv\"))\n",
    "\n",
    "binlens = [10080*60, 1440*60, 360*60, 60*60]\n",
    "oneweek = np.array([])\n",
    "oneday = np.array([])\n",
    "sixhours = np.array([])\n",
    "onehour = np.array([])\n",
    "diff = np.array([])\n",
    "loc_acc = np.array([])\n",
    "\n",
    "# Create dataframe to store temporal distribution\n",
    "temp_distribution = pd.DataFrame(columns=['timestamp', 'unix_min', 'day'])\n",
    "\n",
    "#def parallel_loop(binlens, oneweek, oneday, sixhours, onehour):\n",
    "for i in binlens:\n",
    "    print(\"Start bin length: \", i, \" seconds\")\n",
    "    for file in glob.glob(\"*.csv\"):\n",
    "        Suball = pd.read_csv(folderpath+file,header=0)\n",
    "        Suball['timestamp'] = pd.to_datetime(Suball['timestamp'])\n",
    "        Suball['unix_min'] = Suball['timestamp'].astype(np.int64) // 10**9\n",
    "        Suball = Suball.sort_values(by=['unix_min'])\n",
    "\n",
    "        # Obtain difference between consecutive timestamps\n",
    "        Suball['diff'] = Suball['unix_min'].diff()\n",
    "        #diff = np.append(diff, Suball['diff'])\n",
    "        # Count number of rows with 'diff' > i\n",
    "        cnt = Suball[Suball['diff'] > i].shape[0]\n",
    "\n",
    "        #tempocp = analysis.tempOcp(Suball, unix_col = 'unix_min', bin_len = i)\n",
    "        #print(\"temporal occupancy: \", tempocp)\n",
    "        if i == 10080*60:\n",
    "            oneweek = np.append(oneweek, cnt)\n",
    "        elif i == 1440*60:\n",
    "            oneday = np.append(oneday, cnt)\n",
    "        elif i == 360*60:\n",
    "            sixhours = np.append(sixhours, cnt)\n",
    "        elif i == 60*60:\n",
    "            onehour = np.append(onehour, cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot each numpy array as a histogram\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(oneweek, bins=20)\n",
    "plt.title('1 week')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(oneday, bins=20)\n",
    "plt.title('1 day')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(sixhours, bins=20)\n",
    "plt.title('6 hours')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(onehour, bins=20)\n",
    "plt.title('1 hour')\n",
    "plt.show()\n",
    "\n",
    "# Plot all numpy arrays as a histogram\n",
    "plt.hist(oneweek, bins=20, alpha=0.9, label='1 week', color='C0')\n",
    "plt.hist(oneday, bins=20, alpha=0.6, label='1 day', color='C1')\n",
    "plt.hist(sixhours, bins=20, alpha=0.5, label='6 hours', color='C2')\n",
    "plt.hist(onehour, bins=20, alpha=0.4, label='1 hour', color='C3')\n",
    "# Give x and y titles\n",
    "plt.xlabel('Number of missing periods per user')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(loc='upper right')\n",
    "# Limit to 600 on the y-axis\n",
    "plt.ylim(0, 600)\n",
    "plt.show()\n",
    "\n",
    "# Plot just 1 week, 1 day using same colors as above\n",
    "plt.hist(oneweek, bins=20, alpha=0.9, label='1 week', color='C0')\n",
    "plt.hist(oneday, bins=20, alpha=0.6, label='1 day', color='C1')\n",
    "plt.legend(loc='upper right')\n",
    "# Limit to 600 on the y-axis\n",
    "plt.ylim(0, 600)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See percent of users that have at least one week of missingness\n",
    "print(\"Percent of users that have at least one week of missingness \", len(oneweek[oneweek != 0])/len(oneweek))\n",
    "\n",
    "# See percent of users that have at least one day of missingness\n",
    "print(\"Percent of users that have at least one day of missingness \", len(oneday[oneday != 0])/len(oneday))\n",
    "\n",
    "# See percent of users that have at least six hours of missingness\n",
    "print(\"Percent of users that have at least six hours of missingness \", len(sixhours[sixhours != 0])/len(sixhours))\n",
    "\n",
    "# See percent of users that have at least one hour of missingness\n",
    "print(\"Percent of users that have at least one hour of missingness \", len(onehour[onehour != 0])/len(onehour))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See percent of users that have more than one week of missingness\n",
    "print(\"Percent of users that have at least one week of missingness \", len(oneweek[oneweek > 1])/len(oneweek))\n",
    "\n",
    "# See percent of users that have more than one day of missingness\n",
    "print(\"Percent of users that have at least one day of missingness \", len(oneday[oneday > 1])/len(oneday))\n",
    "\n",
    "# See percent of users that have more than six hours of missingness\n",
    "print(\"Percent of users that have at least six hours of missingness \", len(sixhours[sixhours > 1])/len(sixhours))\n",
    "\n",
    "# See percent of users that have more than one hour of missingness\n",
    "print(\"Percent of users that have at least one hour of missingness \", len(onehour[onehour > 1])/len(onehour))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save numpy arrays to csv\n",
    "np.savetxt(\"oneweek.csv\", oneweek, delimiter=\",\")\n",
    "np.savetxt(\"oneday.csv\", oneday, delimiter=\",\")\n",
    "np.savetxt(\"sixhours.csv\", sixhours, delimiter=\",\")\n",
    "np.savetxt(\"onehour.csv\", onehour, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skmob_alt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3be6a4b976e3fc5992cbda345f874ed08629b5aa1a879cf1954f33c2638a941f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
