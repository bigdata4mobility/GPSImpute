{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trajectory Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import math\n",
    "import torch\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from kneed import KneeLocator\n",
    "from sklearn.cluster import KMeans\n",
    "#from sklearn.metrics import silhouette_score\n",
    "from gpytorch.kernels import RQKernel as RQ, RBFKernel as SE, \\\n",
    "PeriodicKernel as PER, ScaleKernel, LinearKernel as LIN, MaternKernel as MAT, \\\n",
    "SpectralMixtureKernel as SMK, PiecewisePolynomialKernel as PPK, CylindricalKernel as CYL\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import mobileDataToolkit.preprocessing_v2 as preprocessing\n",
    "import mobileDataToolkit.analysis as analysis\n",
    "import mobileDataToolkit.methods as methods\n",
    "import mobileDataToolkit.metrics as metrics\n",
    "import utils.GP as GP\n",
    "import utils.helper_func as helper_func\n",
    "import geopandas as gpd\n",
    "import skmob\n",
    "import skmob.preprocessing.detection\n",
    "import skmob.preprocessing.clustering\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = \"C:/Users/stlp/OneDrive - UW/GPR/Data/newAllTrips_withmetrics.csv\"\n",
    "c_path = \"C:/Users/stlp/OneDrive - UW/GPR/Data/newCompressedTrips.csv\"\n",
    "all_path = \"C:/Users/stlp/OneDrive - UW/GPR/Data/10_users_all_obs_raw.csv\"\n",
    "\n",
    "# Mobility metrics dataset preprocessing\n",
    "m_df = pd.read_csv(c_path, header=0)\n",
    "m_df = m_df.dropna()\n",
    "\n",
    "# Filter out trips with unrealistic speeds, durations, and number of points\n",
    "m_df = m_df[(m_df['vel_avg'] < 60) & #no faster than 60 m/s (as the crow flies)\n",
    "            (m_df['time_total'] < 7200) & # no longer than 2 hours\n",
    "            (m_df['npoints'] > 4) & # at least 5 points for modeling\n",
    "            (m_df['StartDay'] == m_df['EndDay']) # start day and end day must be the same\n",
    "            ]\n",
    "\n",
    "m_df = m_df[m_df['Id_perc'] != 2141084034]\n",
    "\n",
    "feats = m_df[['vel_avg', 'distanceTotal', 'time_total', 'hcr', 'vcr', 'npoints', 'sr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import similaritymeasures\n",
    "\n",
    "n_points = 100\n",
    "\n",
    "# Get regularly sampled points along the trip from linestring object\n",
    "def get_points_from_linestring(ls, n_points=n_points):\n",
    "    # Get the length of the linestring\n",
    "    length = ls.length\n",
    "    # Get the distance between each point\n",
    "    dist = length / n_points\n",
    "    # Get the points\n",
    "    points = [ls.interpolate(i * dist) for i in range(n_points)]\n",
    "    # Convert points to a geodataframe\n",
    "    points_gdf = gpd.GeoDataFrame(geometry=points)\n",
    "    return points_gdf\n",
    "\n",
    "# Do a for loop to get the points for each trip\n",
    "for i in range(len(similar_trips_ls)):\n",
    "    similar_trips_points.append(get_points_from_linestring(similar_trips_ls[i]))\n",
    "    \n",
    "\n",
    "# Get the points along the trip\n",
    "trip1_points = get_points_from_linestring(trip1_ls)\n",
    "similar_trips_points = [get_points_from_linestring(i) for i in similar_trips_ls]\n",
    "\n",
    "trip1_points_arr = np.zeros((100, 2))\n",
    "trip1_points_arr[:, 0] = trip1_points.geometry.x\n",
    "trip1_points_arr[:, 1] = trip1_points.geometry.y\n",
    "\n",
    "similar_trips_points_arr = np.zeros((100, 2))\n",
    "similar_trips_points_arr[:, 0] = similar_trips_points[0].geometry.x\n",
    "similar_trips_points_arr[:, 1] = similar_trips_points[0].geometry.y\n",
    "\n",
    "#trip1_pts = np.zeros((n_points = 100, 2))\n",
    "#num_data[:, 0] = trip1_points.geometry.x\n",
    "#num_data[:, 1] = trip1_points.geometry.y\n",
    "\n",
    "# quantify the difference between the two curves using PCM\n",
    "pcm = similaritymeasures.pcm(trip1_points_arr, similar_trips_points_arr)\n",
    "\n",
    "# quantify the difference between the two curves using\n",
    "# Discrete Frechet distance\n",
    "df = similaritymeasures.frechet_dist(trip1_points_arr, similar_trips_points_arr)\n",
    "\n",
    "# quantify the difference between the two curves using\n",
    "# area between two curves\n",
    "area = similaritymeasures.area_between_two_curves(trip1_points_arr, similar_trips_points_arr)\n",
    "\n",
    "# quantify the difference between the two curves using\n",
    "# Curve Length based similarity measure\n",
    "cl = similaritymeasures.curve_length_measure(trip1_points_arr, similar_trips_points_arr)\n",
    "\n",
    "# quantify the difference between the two curves using\n",
    "# Dynamic Time Warping distance\n",
    "dtw, d = similaritymeasures.dtw(trip1_points_arr, similar_trips_points_arr)\n",
    "\n",
    "# mean absolute error\n",
    "mae = similaritymeasures.mae(trip1_points_arr, similar_trips_points_arr)\n",
    "\n",
    "# mean squared error\n",
    "mse = similaritymeasures.mse(trip1_points_arr, similar_trips_points_arr)\n",
    "\n",
    "# print the results\n",
    "print(pcm, df, area, cl, dtw, mae, mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapely\n",
    "from shapely.geometry import LineString\n",
    "\n",
    "# Create linestring objects for each trip\n",
    "trip1_ls = LineString(zip(tr_df.data[tr_df.data['trip_ID'] == trip1['trip_ID'].iloc[0]]['lng'], tr_df.data[tr_df.data['trip_ID'] == trip1['trip_ID'].iloc[0]]['lat']))\n",
    "similar_trips_ls = [LineString(zip(tr_df.data[tr_df.data['trip_ID'] == j]['lng'], tr_df.data[tr_df.data['trip_ID'] == j]['lat'])) for j in np.setdiff1d(tr_df.data['trip_ID'].unique(), trip1['trip_ID'].unique())]\n",
    "\n",
    "# Calculate the distance between trip1 and each similar trip\n",
    "distances = [trip1_ls.distance(i) for i in similar_trips_ls]\n",
    "print(distances)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
